{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [Multilevel Modeling](https://en.wikipedia.org/wiki/Multilevel_model)\n",
    "Idea: Decompose the sum of random numbers into its contributions & use a custom distribution\n",
    "\n",
    "for a given set of $x_i$ and $a_{ik}$ with\n",
    "$$x_i = \\Sigma_{j=0}^n \\Sigma_{k=1}^{m_j} a_{ik}y_{jk}$$ \n",
    "with\n",
    "* $m_j$ being the number of contributers of layer j\n",
    "* $y_{jk}$ being the k-th contribution of layer j\n",
    "* $m_0 = 1$ by default\n",
    "* $a_{ik} \\in \\{0, 1\\}$\n",
    "* $\\Sigma a_{ik} = 1$ only one contributer per layer\n",
    "\n",
    "calculate the Distributions $y_{k} \\sim N(μ_{k}, σ_{k})$\n",
    "Boundary conditions:\n",
    "* $\\Sigma _{k} μ_k = 0$ via $μ_{m_j} = -\\Sigma_{k = 1}^{m_j-1} μ_{k}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "#import os\n",
    "import warnings\n",
    "import matplotlib.pyplot as plt\n",
    "import logging\n",
    "import seaborn as sns\n",
    "import pymc as pm\n",
    "import arviz as az\n",
    "import pytensor as pt\n",
    "import pytensor #inelegant :-(\n",
    "#import pandas as pd\n",
    "#import pymc.sampling_jax as sampling_jax\n",
    "import nutpie\n",
    "\n",
    "%matplotlib inline\n",
    "plt.style.use('default')\n",
    "\n",
    "#logging.basicConfig(format='%(message)s', level=logging.INFO)\n",
    "warnings.filterwarnings(\"ignore\", module=\"scipy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on PyMC v5.16.2\n"
     ]
    }
   ],
   "source": [
    "print(f\"Running on PyMC v{pm.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples = 10000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## setup the individual random generators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def align_coefficients(coefs):\n",
    "    \"\"\"ensure that the average over all contributers per level is 0\"\"\"\n",
    "    mem = []\n",
    "    for lcoefs in coefs:\n",
    "        avg = np.mean([m for (m, s) in lcoefs.values()])\n",
    "        mem.append({k: (m-avg, s) for k, (m,s) in lcoefs.items()})\n",
    "    \n",
    "    return mem\n",
    "\n",
    "def gen_contributer_coefficients(n_contributers, contributer_avg, contributer_sig):\n",
    "    \"\"\"creates for n_contributers the average and standard deviation\n",
    "    Input:\n",
    "    * n_contributers: list with number of influencers for each level\n",
    "    * contributer_avg: average for the average of the influencers\n",
    "    * contributer_sig: average for the stdev for the influencers (lognormal distribution) \n",
    "     \n",
    "    Output:\n",
    "    Dictionary {level : { influencer: (mu, sigma)}} with the coefficients for every\n",
    "    influencer in each level\n",
    "    \"\"\"\n",
    "    assert n_contributers[0] == 1, \"First level is allowed to have one contributer\"\n",
    "    return align_coefficients([{i : (np.random.normal(contributer_avg), np.random.lognormal(contributer_sig)) for i in range(num)} for lvl, num in enumerate(n_contributers)])\n",
    "\n",
    "def print_coefficients(contributer_coefficients):\n",
    "    contributer_coefficients = align_coefficients(contributer_coefficients)\n",
    "    for m, stage in enumerate(contributer_coefficients):\n",
    "        for i, (mu, sig) in stage.items():\n",
    "            print(f\"Stage {m}: Contributer {i} mu={mu:.2f}, sig={sig:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# easy as a start\n",
    "\n",
    "cc_12 = [\n",
    "    {    0 : (0, 5)},\n",
    "    {    0: (1, 1),\n",
    "        1: (-1, 1)}\n",
    "        ]\n",
    "cc_22 = [\n",
    "    {    0 : (0, 5)},\n",
    "    {    0: (1, 1),\n",
    "        1: (-1, 1)},\n",
    "    {    0: (1, 1),\n",
    "        1: (-1, 1)}\n",
    "        ]\n",
    "cc_27 = [\n",
    "    {    0 : (0, 5)},\n",
    "    {    0: (1, 1),\n",
    "        1: (-1, 1),\n",
    "        2: (4, 1)},\n",
    "    {    0: (3, 1),\n",
    "        1: (-1, 1),\n",
    "        2: (-1, 1),\n",
    "        3: (-1, 1)}\n",
    "        ]\n",
    "cc_14 = [{    0: (0, 5)},\n",
    "        {    0: (0, 1),\n",
    "                1: (0, 1),\n",
    "                2: (0, 1),\n",
    "                3: (4, 2)}]\n",
    "cc_343 = [{    0: (0, 5)},\n",
    "        {    0: (0, 1),\n",
    "                1: (0, 1),\n",
    "                2: (0, 1),\n",
    "                3: (4, 2)},\n",
    "            {    0: (0, 1),\n",
    "                1: (0, 1),\n",
    "                3: (3, 2)}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stage 0: Contributer 0 mu=0.00, sig=5.00\n",
      "Stage 1: Contributer 0 mu=-1.00, sig=1.00\n",
      "Stage 1: Contributer 1 mu=-1.00, sig=1.00\n",
      "Stage 1: Contributer 2 mu=-1.00, sig=1.00\n",
      "Stage 1: Contributer 3 mu=3.00, sig=2.00\n",
      "Stage 2: Contributer 0 mu=-1.00, sig=1.00\n",
      "Stage 2: Contributer 1 mu=-1.00, sig=1.00\n",
      "Stage 2: Contributer 3 mu=2.00, sig=2.00\n"
     ]
    }
   ],
   "source": [
    "print_coefficients(cc_343)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_data(contributer_coefficients, n_samples):\n",
    "    \"\"\"generate random data.\n",
    "    The first level defines the baseline that holds for all random numbers\n",
    "    \n",
    "    Inputs:\n",
    "    * n_samples: number of samples\n",
    "    * contributer_coefficients: dictionary with (mean,sig) per level per contributer\n",
    "    \n",
    "    Outputs:\n",
    "    * data: array with the final number\n",
    "    * contributers: matrix defining the contributers, first column is for the first level\"\"\"\n",
    "    \n",
    "    assert len(contributer_coefficients[0]) == 1, \"Level 0 defines the baseline. It should have exactly one contributer\"\n",
    "    #data = np.random.normal(gen_avg, gen_sig, n_samples)\n",
    "    data = np.zeros((n_samples, ))\n",
    "    contributers = np.zeros((n_samples, len(contributer_coefficients)))\n",
    "    for lvl, cdict in enumerate(contributer_coefficients):\n",
    "        print(f\"creating level {lvl}\")\n",
    "        lvl_influencers = len(cdict) #number of influencers in this level\n",
    "        lvldata = np.zeros((n_samples, lvl_influencers))\n",
    "\n",
    "        for i, (mu,sig) in cdict.items():\n",
    "            lvldata[:,i] = np.random.normal(mu, sig, n_samples)\n",
    "\n",
    "        selection = np.random.randint(low=0,\n",
    "                                    high=lvl_influencers,\n",
    "                                    size=(n_samples))\n",
    "        contributers[:, lvl] = selection\n",
    "        \n",
    "        data += np.array([lvldata[row, col] for row, col in enumerate(selection)])\n",
    "        # Note: The first level \n",
    "    return data, contributers[:, 1:].astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling\n",
    "\n",
    "use [Radon Analysis](https://www.pymc.io/projects/examples/en/latest/generalized_linear_models/multilevel_modeling.html) as reference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_model(model, **kwargs):\n",
    "    print(\"start compilation\")\n",
    "    compiled_model = nutpie.compile_pymc_model(model)\n",
    "    print(\"model is compiled\")\n",
    "    trace = nutpie.sample(\n",
    "        compiled_model,\n",
    "        **kwargs\n",
    "        )\n",
    "    return trace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze(trace):\n",
    "    az.summary(trace, round_to=2)\n",
    "    az.plot_trace(trace,\n",
    "              compact=\"true\",\n",
    "    chain_prop={\"ls\": \"-\"},)\n",
    "\n",
    "    \n",
    "    fig = plt.gcf()\n",
    "    fig.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate(n_samples, contributer_coefficients):\n",
    "    if contributer_coefficients == 2:\n",
    "        n_contributers= len(contributer_coefficients[1])\n",
    "        print(\"ATTENTION: just for one level\")\n",
    "    else:\n",
    "        n_contributers = [len(level) for level in contributer_coefficients][1:]\n",
    "\n",
    "    data, contributers = gen_data(n_samples=n_samples,\n",
    "                              contributer_coefficients=contributer_coefficients)\n",
    "\n",
    "    #contributers = contributers.squeeze(-1) # kill the first level - not needed\n",
    "    return data, contributers, n_contributers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating level 0\n",
      "creating level 1\n",
      "creating level 0\n",
      "creating level 1\n",
      "creating level 2\n"
     ]
    }
   ],
   "source": [
    "# generate the data\n",
    "data0, contributers0, n_contributers0 = generate(n_samples=n_samples, contributer_coefficients=cc_14)\n",
    "data, contributers, n_contributers = generate(n_samples=n_samples, contributer_coefficients=cc_27)\n",
    "\n",
    "contributers0 = contributers0.squeeze(-1) # for the 1 level version\n",
    "n_contributers0 = n_contributers0[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [Custom Distribution](https://www.pymc.io/projects/docs/en/latest/contributing/implementing_distribution.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymc.distributions.distribution import DIST_PARAMETER_TYPES, Continuous\n",
    "from pytensor.tensor.random.basic import normal\n",
    "from pymc.distributions.shape_utils import rv_size_is_none\n",
    "from pymc.distributions.dist_math import (\n",
    "\n",
    "    check_icdf_parameters,\n",
    "    check_icdf_value,\n",
    "    check_parameters,\n",
    "    normal_lcdf\n",
    ")\n",
    "\n",
    "class fixedStdNormal(Continuous):\n",
    "    r\"\"\"\n",
    "    Standard Normal Distribution --> The solver will not use it for optimization\n",
    "    \"\"\"\n",
    "\n",
    "    rv_op = normal\n",
    "\n",
    "\n",
    "    @classmethod\n",
    "    def dist(cls, **kwargs):\n",
    "\n",
    "\n",
    "        # tau = pt.as_tensor_variable(tau)\n",
    "        # mean = median = mode = mu = pt.as_tensor_variable(floatX(mu))\n",
    "        # variance = 1.0 / self.tau\n",
    "\n",
    "        #return super().dist([0, 1], **kwargs)\n",
    "        return super().dist([], **kwargs)\n",
    "\n",
    "\n",
    "\n",
    "    def support_point(rv, size):\n",
    "        #mu, _ = pt.broadcast_arrays(mu, sigma)\n",
    "        mu = 0\n",
    "        if not rv_size_is_none(size):\n",
    "            mu = pt.full(size, 0)\n",
    "        return mu\n",
    "\n",
    "    def logp(value):\n",
    "        mu, sigma = 0 , 1\n",
    "        res = -0.5 * pt.pow((value - mu) / sigma, 2) - pt.log(pt.sqrt(2.0 * np.pi)) - pt.log(sigma)\n",
    "        return check_parameters(\n",
    "            res,\n",
    "            sigma > 0,\n",
    "            msg=\"sigma > 0\",\n",
    "        )\n",
    "\n",
    "    def logcdf(value):\n",
    "        mu, sigma = 0 , 1\n",
    "        return check_parameters(\n",
    "            normal_lcdf(mu, sigma, value),\n",
    "            sigma > 0,\n",
    "            msg=\"sigma > 0\",\n",
    "        )\n",
    "\n",
    "    def icdf(value):\n",
    "        mu, sigma = 0 , 1\n",
    "        res = mu + sigma * -np.sqrt(2.0) * pt.erfcinv(2 * value)\n",
    "        res = check_icdf_value(res, value)\n",
    "        return check_icdf_parameters(\n",
    "            res,\n",
    "            sigma > 0,\n",
    "            msg=\"sigma > 0\",\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 5\n",
    "samples = 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_faker(n, samples, mu_a=3, sig_a=5, sig_b=1):\n",
    "    xdata = np.random.normal(mu_a, sig_a, samples)\n",
    "    bdata = np.random.randint(low=0, high=n, size=(samples))\n",
    "    mu = np.arange(0, n)-(n-1)/2\n",
    "    for i,m in enumerate(mu):\n",
    "        xdata += np.where(bdata == i, np.random.normal(m, sig_b, samples), 0)\n",
    "    \n",
    "    return xdata, bdata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "xdata, bdata = data_faker(n, samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Incompatible parametrization. Must specify either lam or scale.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 11\u001b[0m\n\u001b[0;32m      8\u001b[0m sigma_a\u001b[38;5;241m=\u001b[39m pm\u001b[38;5;241m.\u001b[39mExponential(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msigma_a\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m     10\u001b[0m \u001b[38;5;66;03m# level 1\u001b[39;00m\n\u001b[1;32m---> 11\u001b[0m mu_c \u001b[38;5;241m=\u001b[39m \u001b[43mpm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mExponential\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmu_c\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshape\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     12\u001b[0m sigma_c\u001b[38;5;241m=\u001b[39m pm\u001b[38;5;241m.\u001b[39mExponential(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msigma_c\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m1\u001b[39m, shape\u001b[38;5;241m=\u001b[39mn)\n\u001b[0;32m     14\u001b[0m \u001b[38;5;66;03m# reparametrization\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\fuerf\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pymc\\distributions\\distribution.py:536\u001b[0m, in \u001b[0;36mDistribution.__new__\u001b[1;34m(cls, name, rng, dims, initval, observed, total_size, transform, default_transform, *args, **kwargs)\u001b[0m\n\u001b[0;32m    533\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m observed \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    534\u001b[0m         kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mshape\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtuple\u001b[39m(observed\u001b[38;5;241m.\u001b[39mshape)\n\u001b[1;32m--> 536\u001b[0m rv_out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdist\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    538\u001b[0m rv_out \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mregister_rv(\n\u001b[0;32m    539\u001b[0m     rv_out,\n\u001b[0;32m    540\u001b[0m     name,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    546\u001b[0m     initval\u001b[38;5;241m=\u001b[39minitval,\n\u001b[0;32m    547\u001b[0m )\n\u001b[0;32m    549\u001b[0m \u001b[38;5;66;03m# add in pretty-printing support\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\fuerf\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pymc\\distributions\\continuous.py:1393\u001b[0m, in \u001b[0;36mExponential.dist\u001b[1;34m(cls, lam, scale, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1391\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIncompatible parametrization. Can\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt specify both lam and scale.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   1392\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m lam \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m scale \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1393\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIncompatible parametrization. Must specify either lam or scale.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   1395\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m scale \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   1396\u001b[0m     scale \u001b[38;5;241m=\u001b[39m pt\u001b[38;5;241m.\u001b[39mreciprocal(lam)\n",
      "\u001b[1;31mValueError\u001b[0m: Incompatible parametrization. Must specify either lam or scale."
     ]
    }
   ],
   "source": [
    "with pm.Model() as model_fixedSN:\n",
    "    #Input data\n",
    "    x = pm.Data(\"x\", xdata, dims=\"obs_id\")\n",
    "    b = pm.Data(\"b\", bdata, dims=\"obs_id\")\n",
    "    \n",
    "    #baseline\n",
    "    mu_a = pm.Normal(\"mu_a \", mu=0.0, sigma=10)\n",
    "    sigma_a= pm.Exponential(\"sigma_a\", 1)\n",
    "\n",
    "    # level 1\n",
    "    mu_c = pm.Exponential(f\"mu_c\", shape=n)\n",
    "    sigma_c= pm.Exponential(\"sigma_c\", 1, shape=n)\n",
    "\n",
    "    # reparametrization\n",
    "    c_dist = fixedStdNormal(\"c_dist\", shape=n)\n",
    "    c = pm.Deterministic(\"c\", mu_c + sigma_c * c_dist)\n",
    "\n",
    "    y_hat = mu_a + c[b]\n",
    "\n",
    "    # value\n",
    "    value = pm.Normal(\"value\", \n",
    "                      mu=y_hat,\n",
    "                      sigma = sigma_a,\n",
    "                      observed = x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trace = run_model(model_fixedSN)\n",
    "analyze(trace)\n",
    "az.summary(trace, round_to=2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
