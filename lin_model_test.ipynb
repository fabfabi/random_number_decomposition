{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [Multilevel Modeling](https://en.wikipedia.org/wiki/Multilevel_model)\n",
    "Idea: Decompose the sum of random numbers into its contributions\n",
    "\n",
    "for a given set of $x_i$ and $a_{ik}$ with\n",
    "$$x_i = \\Sigma_{j=0}^n \\Sigma_{k=1}^{m_j} a_{ik}y_{jk}$$ \n",
    "with\n",
    "* $m_j$ being the number of contributers of layer j\n",
    "* $y_{jk}$ being the k-th contribution of layer j\n",
    "* $m_0 = 1$ by default\n",
    "* $a_{ik} \\in \\{0, 1\\}$\n",
    "* $\\Sigma a_{ik} = 1$ only one contributer per layer\n",
    "\n",
    "calculate the Distributions $y_{k} \\sim N(μ_{k}, σ_{k})$\n",
    "Boundary conditions:\n",
    "* $\\Sigma _{k} μ_k = 0$ via $μ_{m_j} = -\\Sigma_{k = 1}^{m_j-1} μ_{k}$\n",
    "\n",
    "\n",
    "Goal of this workbook to explore [Linear Models](https://scikit-learn.org/stable/modules/linear_model.html) see also [(Examples)](https://scikit-learn.org/stable/auto_examples/linear_model/index.html)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import sklearn\n",
    "from sklearn import linear_model\n",
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def align_coefficients(coefs):\n",
    "    \"\"\"ensure that the average over all contributers per level is 0\"\"\"\n",
    "    mem = []\n",
    "    for lcoefs in coefs:\n",
    "        avg = np.mean([m for (m, s) in lcoefs.values()])\n",
    "        mem.append({k: (m-avg, s) for k, (m,s) in lcoefs.items()})\n",
    "    \n",
    "    return mem\n",
    "\n",
    "def gen_contributer_coefficients(n_contributers, contributer_avg, contributer_sig):\n",
    "    \"\"\"creates for n_contributers the average and standard deviation\n",
    "    Input:\n",
    "    * n_contributers: list with number of influencers for each level\n",
    "    * contributer_avg: average for the average of the influencers\n",
    "    * contributer_sig: average for the stdev for the influencers (lognormal distribution) \n",
    "     \n",
    "    Output:\n",
    "    Dictionary {level : { influencer: (mu, sigma)}} with the coefficients for every\n",
    "    influencer in each level\n",
    "    \"\"\"\n",
    "    assert n_contributers[0] == 1, \"First level is allowed to have one contributer\"\n",
    "    return [{i : (np.random.normal(contributer_avg), np.random.lognormal(contributer_sig)) for i in range(num)} for lvl, num in enumerate(n_contributers)]\n",
    "    return align_coefficients([{i : (np.random.normal(contributer_avg), np.random.lognormal(contributer_sig)) for i in range(num)} for lvl, num in enumerate(n_contributers)])\n",
    "\n",
    "def print_coefficients(contributer_coefficients):\n",
    "    #contributer_coefficients = align_coefficients(contributer_coefficients)\n",
    "    for m, stage in enumerate(contributer_coefficients):\n",
    "        for i, (mu, sig) in stage.items():\n",
    "            print(f\"Stage {m}: Contributer {i} mu={mu:.2f}, sig={sig:.2f}\")\n",
    "\n",
    "def gen_data(contributer_coefficients, n_samples):\n",
    "    \"\"\"generate random data.\n",
    "    The first level defines the baseline that holds for all random numbers\n",
    "    \n",
    "    Inputs:\n",
    "    * n_samples: number of samples\n",
    "    * contributer_coefficients: dictionary with (mean,sig) per level per contributer\n",
    "    \n",
    "    Outputs:\n",
    "    * data: array with the final number\n",
    "    * contributers: matrix defining the contributers, first column is for the first level\"\"\"\n",
    "    \n",
    "    assert len(contributer_coefficients[0]) == 1, \"Level 0 defines the baseline. It should have exactly one contributer\"\n",
    "    #data = np.random.normal(gen_avg, gen_sig, n_samples)\n",
    "    data = np.zeros((n_samples, ))\n",
    "    contributers = np.zeros((n_samples, len(contributer_coefficients)))\n",
    "    for lvl, cdict in enumerate(contributer_coefficients):\n",
    "        #print(f\"creating level {lvl}\")\n",
    "        lvl_influencers = len(cdict) #number of influencers in this level\n",
    "        lvldata = np.zeros((n_samples, lvl_influencers))\n",
    "\n",
    "        for i, (mu,sig) in cdict.items():\n",
    "            lvldata[:,i] = np.random.normal(mu, sig, n_samples)\n",
    "\n",
    "        selection = np.random.randint(low=0,\n",
    "                                    high=lvl_influencers,\n",
    "                                    size=(n_samples))\n",
    "        contributers[:, lvl] = selection\n",
    "        \n",
    "        data += np.array([lvldata[row, col] for row, col in enumerate(selection)])\n",
    "        # Note: The first level \n",
    "    return data, contributers[:, 1:].astype(int)\n",
    "\n",
    "def generate(n_samples, contributer_coefficients):\n",
    "    if contributer_coefficients == 2:\n",
    "        n_contributers= len(contributer_coefficients[1])\n",
    "        print(\"ATTENTION: just for one level\")\n",
    "    else:\n",
    "        n_contributers = [len(level) for level in contributer_coefficients][1:]\n",
    "\n",
    "    print(\"generating Data for\")\n",
    "    print_coefficients(contributer_coefficients)\n",
    "\n",
    "    data, contributers = gen_data(n_samples=n_samples,\n",
    "                              contributer_coefficients=contributer_coefficients)\n",
    "\n",
    "    #contributers = contributers.squeeze(-1) # kill the first level - not needed\n",
    "    return data, contributers, n_contributers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generating Data for\n",
      "Stage 0: Contributer 0 mu=2.00, sig=5.00\n",
      "Stage 1: Contributer 0 mu=2.00, sig=1.00\n",
      "Stage 1: Contributer 1 mu=-1.00, sig=1.00\n",
      "Stage 1: Contributer 2 mu=-1.00, sig=3.00\n",
      "Stage 2: Contributer 0 mu=2.00, sig=1.00\n",
      "Stage 2: Contributer 1 mu=-1.00, sig=1.00\n",
      "Stage 2: Contributer 2 mu=-1.00, sig=1.00\n",
      "Stage 2: Contributer 3 mu=0.00, sig=1.00\n",
      "number of features: 7\n"
     ]
    }
   ],
   "source": [
    "n_samples = 100000\n",
    "\n",
    "cc_27 = [\n",
    "    {    0 : (2, 5)},\n",
    "    {    0: (2, 1),\n",
    "        1: (-1, 1),\n",
    "        2: (-1, 1)},\n",
    "    {    0: (3, 1),\n",
    "        1: (-1, 1),\n",
    "        2: (-1, 1),\n",
    "        3: (-1, 1)}\n",
    "        ]\n",
    "\n",
    "cc_27b = [\n",
    "    {    0 : (2, 5)},\n",
    "    {    0: (2, 1),\n",
    "        1: (-1, 1),\n",
    "        2: (-1, 3)},\n",
    "    {    0: (2, 1),\n",
    "        1: (-1, 1),\n",
    "        2: (-1, 1),\n",
    "        3: (0, 1)}\n",
    "        ]\n",
    "\n",
    "\n",
    "data, contributers, n_contributers = generate(n_samples, contributer_coefficients=cc_27b)\n",
    "\n",
    "enc = OneHotEncoder(handle_unknown='ignore')\n",
    "enc.fit(contributers)\n",
    "contributers_ohe = enc.transform(contributers).toarray()\n",
    "n_features = np.sum(n_contributers)\n",
    "print(f\"number of features: {n_features}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show(coefficients, text = \"\"):\n",
    "\n",
    "    l = list(coefficients)\n",
    "    p = lambda i: [f\"{l.pop(0):.3f}\" for _ in range(i)]\n",
    "    print(text) if text != \"\" else \"\"\n",
    "    \n",
    "    for i,n in enumerate(n_contributers):\n",
    "        print(f\"{i}: {p(n)}\")\n",
    "        \n",
    "def eval(regressor, n_contributers=n_contributers):\n",
    "    \"\"\"print intercept and coefficients\"\"\"\n",
    "    print(f\"Intercept: {regressor.intercept_}\")\n",
    "    show(regressor.coef_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [Ridge Regression](https://scikit-learn.org/stable/modules/linear_model.html#regression)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intercept: 1.9681512365785025\n",
      "0: ['1.908', '-0.932', '-0.975']\n",
      "1: ['2.177', '-1.042', '-1.012', '-0.123']\n"
     ]
    }
   ],
   "source": [
    "reg = linear_model.Ridge(alpha=1, fit_intercept=True)\n",
    "reg.fit(contributers_ohe, data)\n",
    "eval(reg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [Lasso](https://scikit-learn.org/stable/modules/linear_model.html#lasso)\n",
    "--> [LassoLarsCV](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LassoLarsCV.html#sklearn.linear_model.LassoLarsCV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intercept: 0.886657158656976\n",
      "0: ['2.821', '0.000', '-0.023']\n",
      "1: ['2.301', '-0.866', '-0.838', '0.000']\n"
     ]
    }
   ],
   "source": [
    "reg = linear_model.LassoLarsCV(cv=5).fit(contributers_ohe, data)\n",
    "reg.score(contributers_ohe, data)\n",
    "eval(reg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [Elastic-Net](https://scikit-learn.org/stable/modules/linear_model.html#elastic-net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intercept: 1.4958976611423003\n",
      "0: ['2.250', '-0.581', '-0.625']\n",
      "1: ['2.294', '-0.913', '-0.884', '0.000']\n"
     ]
    }
   ],
   "source": [
    "reg = linear_model.ElasticNetCV(cv=5).fit(contributers_ohe, data)\n",
    "eval(reg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [LARS-Lasso](https://scikit-learn.org/stable/modules/linear_model.html#lars-lasso)\n",
    "--> finds biggest contributers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intercept: 0.6458608897258027\n",
      "0: ['2.419', '0.000', '0.000']\n",
      "1: ['2.295', '-0.108', '-0.117', '0.000']\n"
     ]
    }
   ],
   "source": [
    "reg = linear_model.LassoLars(alpha=0.1).fit(contributers_ohe, data)\n",
    "eval(reg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [Orthogonal Matching Pursuit](https://scikit-learn.org/stable/modules/linear_model.html#orthogonal-matching-pursuit-omp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intercept: 1.1001706748930251\n",
      "0: [2.865314887852755, 0.0, 0.0]\n",
      "1: [0.0, 0.0, 0.0, 0.0]\n"
     ]
    }
   ],
   "source": [
    "reg = linear_model.OrthogonalMatchingPursuit().fit(contributers_ohe, data)\n",
    "eval(reg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [Bayesian Ridge Regression](https://scikit-learn.org/stable/modules/linear_model.html#bayesian-ridge-regression)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Convergence after  2  iterations\n",
      "Intercept: 1.9903518245545497\n",
      "0: ['2.003', '-0.987', '-1.016']\n",
      "1: ['2.035', '-1.037', '-0.988', '-0.010']\n",
      "precision of the noise: 0.033596669987209934\n",
      "Estimated precision of the weights: 0.40927591723407725\n",
      "Estimated variance-covariance matrix of the weights: [[ 8.15039474e-01  8.14152385e-01  8.14147604e-01  3.27145415e-06\n",
      "  -4.27959187e-06 -4.91017499e-07  1.49915522e-06]\n",
      " [ 8.14152385e-01  8.15040319e-01  8.14146759e-01 -5.08046494e-06\n",
      "   3.70194365e-06  9.15845238e-07  4.62676057e-07]\n",
      " [ 8.14147604e-01  8.14146759e-01  8.15045100e-01  1.80901079e-06\n",
      "   5.77648226e-07 -4.24827741e-07 -1.96183127e-06]\n",
      " [ 3.27145415e-06 -5.08046494e-06  1.80901079e-06  6.11724678e-01\n",
      "   6.10537209e-01  6.10539123e-01  6.10538453e-01]\n",
      " [-4.27959187e-06  3.70194365e-06  5.77648226e-07  6.10537209e-01\n",
      "   6.11730405e-01  6.10536270e-01  6.10535579e-01]\n",
      " [-4.91017499e-07  9.15845238e-07 -4.24827741e-07  6.10539123e-01\n",
      "   6.10536270e-01  6.11726598e-01  6.10537473e-01]\n",
      " [ 1.49915522e-06  4.62676057e-07 -1.96183127e-06  6.10538453e-01\n",
      "   6.10535579e-01  6.10537473e-01  6.11727959e-01]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "reg = linear_model.BayesianRidge(verbose=True).fit(contributers_ohe, data)\n",
    "eval(reg)\n",
    "\n",
    "print(f\"precision of the noise: {reg.alpha_}\")\n",
    "print(f\"Estimated precision of the weights: {reg.lambda_}\")\n",
    "print(f\"Estimated variance-covariance matrix of the weights: {reg.sigma_}\")\n",
    "print(f\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [Auomatic Relevance Determination](https://scikit-learn.org/stable/modules/linear_model.html#automatic-relevance-determination-ard)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converged after 49 iterations\n",
      "Intercept: -0.0195114002739758\n",
      "0: ['3.005', '0.000', '0.000']\n",
      "1: ['3.044', '-0.008', '0.000', '0.997']\n",
      "precision of the noise: 0.033596888807175006\n",
      "Estimated precision of the weights:\n",
      "0: ['0.111', '12385.628', '11902.197']\n",
      "1: ['0.108', '2341.851', '130831.296', '1.005']\n",
      "Estimated variance-covariance matrix of the weights:\n",
      " [[ 1.33445803e-03  8.08229456e-06 -8.65594155e-07  5.37931777e-06]\n",
      " [ 8.08229456e-06  1.87065032e-03  1.80352290e-04  6.84965547e-04]\n",
      " [-8.65594155e-07  1.80352290e-04  3.62147387e-04  1.80161405e-04]\n",
      " [ 5.37931777e-06  6.84965547e-04  1.80161405e-04  1.87452842e-03]]\n",
      "Scores\n",
      "[-219681.28420304903, -219684.744744543, -219679.26014689074, -219679.38364089004, -219680.1884062983, -219675.75162674865, -219675.9051049339, -219671.33456588793, -219671.334836234, -219671.33516932424, -219671.3355691393, -219671.3360370432, -219671.33657528216, -219671.33718692113, -219671.33787586793, -219671.33864690847, -219671.33950574862, -219671.34045905643, -219671.34151448938, -219671.3426806853, -219671.34396717773, -219671.34538416882, -219671.34694204197, -219671.34865040673, -219671.3505163077, -219671.35254092686, -219671.35471354247, -219671.35700040602, -219671.35932400206, -219671.36152362445, -219671.36327853418, -219671.36395348102, -219671.36227660684, -219671.3556391081, -219671.3385000015, -219671.2985704755, -219671.20726236168, -219670.9951033419, -219670.49005025072, -219669.28300200214, -219665.19508546533, -219662.82824645058, -219662.83812406898, -219662.85930391986, -219662.87658659642, -219662.88994288913, -219662.90034659844, -219662.90856093512, -219662.91511398373, -219662.9203747717]\n"
     ]
    }
   ],
   "source": [
    "reg = linear_model.ARDRegression(verbose=True,\n",
    "                                 compute_score=True,\n",
    "                                 ).fit(contributers_ohe, data)\n",
    "eval(reg)\n",
    "\n",
    "print(f\"precision of the noise: {reg.alpha_}\")\n",
    "\n",
    "show(reg.lambda_, \"Estimated precision of the weights:\")\n",
    "\n",
    "print(f\"Estimated variance-covariance matrix of the weights:\\n {reg.sigma_}\")\n",
    "\n",
    "print(\"Scores\")\n",
    "print(reg.scores_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converged after 95 iterations\n",
      "Intercept: -0.022224261144030866\n",
      "0: ['3.005', '0.001', '-0.001']\n",
      "1: ['3.046', '-0.005', '0.003', '1.000']\n",
      "precision of the noise: 0.03359688382044469\n",
      "Estimated precision of the weights:\n",
      "0: ['0.111', '12154.660', '11949.879']\n",
      "1: ['0.108', '3540.244', '5975.120', '0.999']\n",
      "Estimated variance-covariance matrix of the weights:\n",
      " [[ 1.37593184e-03  4.14614249e-05  4.14981777e-05  8.39876613e-06\n",
      "  -5.68126864e-07  3.35510296e-07  5.69530978e-06]\n",
      " [ 4.14614249e-05  7.88166541e-05  3.51516677e-06 -3.81864215e-07\n",
      "   7.47735741e-09 -4.42504902e-09  9.68094102e-09]\n",
      " [ 4.14981777e-05  3.51516677e-06  8.01070693e-05  3.88330287e-07\n",
      "  -7.60023142e-09  4.49777153e-09 -9.89959881e-09]\n",
      " [ 8.39876613e-06 -3.81864215e-07  3.88330287e-07  1.89178675e-03\n",
      "   1.34997060e-04  8.72230795e-05  7.06079033e-04]\n",
      " [-5.68126864e-07  7.47735741e-09 -7.60023142e-09  1.34997060e-04\n",
      "   2.54306920e-04  1.66594423e-05  1.34855001e-04]\n",
      " [ 3.35510296e-07 -4.42504902e-09  4.49777153e-09  8.72230795e-05\n",
      "   1.66594423e-05  1.57473835e-04  8.71297778e-05]\n",
      " [ 5.69530978e-06  9.68094102e-09 -9.89959881e-09  7.06079033e-04\n",
      "   1.34855001e-04  8.71297778e-05  1.89563201e-03]]\n",
      "Scores\n",
      "[-219681.28420304903, -219684.744744543, -219679.26014689074, -219679.38364089004, -219680.20010305883, -219680.47903281354, -219680.64576100465, -219680.76479940207, -219680.7631946737, -219680.7637475363, -219680.76412156856, -219680.76459247607, -219680.76513029996, -219680.76574192022, -219680.76643078748, -219680.76720174224, -219680.7680604828, -219680.76901367703, -219680.77006898122, -219680.77123503207, -219680.77252136217, -219680.77393817325, -219680.7754958489, -219680.77720400086, -219680.77906967935, -219680.78109407815, -219680.783266499, -219680.7855532386, -219680.78787686705, -219680.7900768425, -219680.79183274478, -219680.79250995893, -219680.7908379333, -219680.78421065994, -219680.76709341368, -219680.7272120928, -219680.63601473012, -219680.42412061646, -219679.91971216118, -219678.71418864952, -219674.676043674, -219680.65873979352, -219677.60271955028, -219677.81152031428, -219677.91781499045, -219677.99122814636, -219678.0449546603, -219678.08184664804, -219678.10497793893, -219678.11866856593, -219678.12669063895, -219678.13151364104, -219678.1345436726, -219678.13654149658, -219678.13791817497, -219678.13890176557, -219678.13962419514, -219678.1401656203, -219678.1405772493, -219678.14089335367, -219678.14113780178, -219678.14132775724, -219678.14147586928, -219678.14159163059, -219678.14168226035, -219678.14175330012, -219678.14180903282, -219678.14185278435, -219678.14188714628, -219678.14191414294, -219678.1419353585, -219678.1419520341, -219678.1419651431, -219678.14197544951, -219678.1419835531, -219678.14198992518, -219678.1419949359, -219678.14199887626, -219678.1420019751, -219678.14200441202, -219678.14200632853, -219678.1420078358, -219678.1420090212, -219678.1420099535, -219678.14201068666, -219678.14201126335, -219678.14201171685, -219678.14201207354, -219678.14201235416, -219678.14201257474, -219678.14201274826, -219678.14201288472, -219678.1420129921, -219678.1420130765, -219678.14201314287, -219678.1420131951]\n"
     ]
    }
   ],
   "source": [
    "reg = linear_model.ARDRegression(verbose=True,\n",
    "                                 compute_score=True,\n",
    "                                 threshold_lambda=1e6, \n",
    "                                 tol=1e-8\n",
    "                                 ).fit(contributers_ohe, data)\n",
    "eval(reg)\n",
    "\n",
    "print(f\"precision of the noise: {reg.alpha_}\")\n",
    "\n",
    "show(reg.lambda_, \"Estimated precision of the weights:\")\n",
    "\n",
    "print(f\"Estimated variance-covariance matrix of the weights:\\n {reg.sigma_}\")\n",
    "\n",
    "print(\"Scores\")\n",
    "print(reg.scores_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "D = np.zeros((n_features, n_features))\n",
    "np.fill_diagonal(D, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 2.98313636, -0.02101741, -0.02347963,  3.02407272, -0.02733895,\n",
       "        -0.01941585,  0.97741452]),\n",
       " array([5.45582635, 5.45570748, 5.45570759, 5.45587363, 5.45572356,\n",
       "        5.45571468, 5.45587398]))"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg.predict(D, return_std=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion\n",
    "Best Results are obtained by the Ridge Regression and the Bayesian Ridge Regression if all standard deviations are the same within one level.\n",
    "\n",
    "If the standard deviation changes, the estimation gets artefacts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1,  1, -1, ..., -1,  1, -1], dtype=int64)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_data = np.hstack((contributers_ohe, np.expand_dims(data, axis=1)))\n",
    "clf = sklearn.svm.OneClassSVM(gamma='auto').fit(full_data)\n",
    "clf.predict(full_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.        ,  0.        ,  1.        , ...,  0.        ,\n",
       "         1.        , -0.27646882],\n",
       "       [ 1.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "         1.        ,  5.54752395],\n",
       "       [ 0.        ,  1.        ,  0.        , ...,  0.        ,\n",
       "         1.        ,  5.54658123],\n",
       "       ...,\n",
       "       [ 0.        ,  0.        ,  1.        , ...,  0.        ,\n",
       "         1.        , -2.87074299],\n",
       "       [ 1.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "         0.        ,  2.803585  ],\n",
       "       [ 1.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "         0.        ,  6.56330766]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [Quantile Regressor](https://scikit-learn.org/stable/auto_examples/linear_model/plot_quantile_regression.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n    if quantile == min(quantiles):\\n        out_bounds_predictions = np.logical_or(\\n            out_bounds_predictions, y_pred >= y_normal\\n        )\\n    elif quantile == max(quantiles):\\n        out_bounds_predictions = np.logical_or(\\n            out_bounds_predictions, y_pred <= y_normal\\n        )\\n        '"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = contributers_ohe\n",
    "y = data\n",
    "from sklearn.utils.fixes import parse_version, sp_version\n",
    "\n",
    "# This is line is to avoid incompatibility if older SciPy version.\n",
    "# You should use `solver=\"highs\"` with recent version of SciPy.\n",
    "solver = \"highs\" if sp_version >= parse_version(\"1.6.0\") else \"interior-point\"\n",
    "\n",
    "from sklearn.linear_model import QuantileRegressor\n",
    "\n",
    "quantiles = [0.05, 0.5, 0.95]\n",
    "predictions = {}\n",
    "#out_bounds_predictions = np.zeros_like(y_true_mean, dtype=np.bool_)\n",
    "for quantile in quantiles:\n",
    "    qr = QuantileRegressor(quantile=quantile, alpha=0, solver=solver)\n",
    "    y_pred = qr.fit(X, y).predict(X)\n",
    "    predictions[quantile] = y_pred\n",
    "\"\"\"\n",
    "    if quantile == min(quantiles):\n",
    "        out_bounds_predictions = np.logical_or(\n",
    "            out_bounds_predictions, y_pred >= y_normal\n",
    "        )\n",
    "    elif quantile == max(quantiles):\n",
    "        out_bounds_predictions = np.logical_or(\n",
    "            out_bounds_predictions, y_pred <= y_normal\n",
    "        )\n",
    "        \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0.05: array([-8.59017276, -4.58415179, -7.70880034, ..., -8.59017276,\n",
       "        -2.93747308, -5.25631195]),\n",
       " 0.5: array([1.18534433, 3.93500599, 0.96129069, ..., 1.18534433, 6.07404894,\n",
       "        2.82335316]),\n",
       " 0.95: array([11.27795775, 12.58010155,  9.64836501, ..., 11.27795775,\n",
       "        14.46249496, 11.34803703])}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{0: (2, 5)},\n",
       " {0: (2, 1), 1: (-1, 1), 2: (-1, 3)},\n",
       " {0: (2, 1), 1: (-1, 1), 2: (-1, 1), 3: (0, 1)}]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cc_27b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
