{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [Multilevel Modeling](https://en.wikipedia.org/wiki/Multilevel_model)\n",
    "Idea: Decompose the sum of random numbers into its contributions\n",
    "\n",
    "for a given set of $x_i$ and $a_{ik}$ with\n",
    "$$x_i = \\Sigma_{j=0}^n \\Sigma_{k=1}^{m_j} a_{ik}y_{jk}$$ \n",
    "with\n",
    "* $m_j$ being the number of contributers of layer j\n",
    "* $y_{jk}$ being the k-th contribution of layer j\n",
    "* $m_0 = 1$ by default\n",
    "* $a_{ik} \\in \\{0, 1\\}$\n",
    "* $\\Sigma a_{ik} = 1$ only one contributer per layer\n",
    "\n",
    "calculate the Distributions $y_{k} \\sim N(μ_{k}, σ_{k})$\n",
    "Boundary conditions:\n",
    "* $\\Sigma _{k} μ_k = 0$ via $μ_{m_j} = -\\Sigma_{k = 1}^{m_j-1} μ_{k}$\n",
    "\n",
    "\n",
    "Goal of this workbook to explore [Linear Models](https://scikit-learn.org/stable/modules/linear_model.html) see also [(Examples)](https://scikit-learn.org/stable/auto_examples/linear_model/index.html)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn import linear_model\n",
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "def align_coefficients(coefs):\n",
    "    \"\"\"ensure that the average over all contributers per level is 0\"\"\"\n",
    "    mem = []\n",
    "    for lcoefs in coefs:\n",
    "        avg = np.mean([m for (m, s) in lcoefs.values()])\n",
    "        mem.append({k: (m-avg, s) for k, (m,s) in lcoefs.items()})\n",
    "    \n",
    "    return mem\n",
    "\n",
    "def gen_contributer_coefficients(n_contributers, contributer_avg, contributer_sig):\n",
    "    \"\"\"creates for n_contributers the average and standard deviation\n",
    "    Input:\n",
    "    * n_contributers: list with number of influencers for each level\n",
    "    * contributer_avg: average for the average of the influencers\n",
    "    * contributer_sig: average for the stdev for the influencers (lognormal distribution) \n",
    "     \n",
    "    Output:\n",
    "    Dictionary {level : { influencer: (mu, sigma)}} with the coefficients for every\n",
    "    influencer in each level\n",
    "    \"\"\"\n",
    "    assert n_contributers[0] == 1, \"First level is allowed to have one contributer\"\n",
    "    return align_coefficients([{i : (np.random.normal(contributer_avg), np.random.lognormal(contributer_sig)) for i in range(num)} for lvl, num in enumerate(n_contributers)])\n",
    "\n",
    "def print_coefficients(contributer_coefficients):\n",
    "    contributer_coefficients = align_coefficients(contributer_coefficients)\n",
    "    for m, stage in enumerate(contributer_coefficients):\n",
    "        for i, (mu, sig) in stage.items():\n",
    "            print(f\"Stage {m}: Contributer {i} mu={mu:.2f}, sig={sig:.2f}\")\n",
    "\n",
    "def gen_data(contributer_coefficients, n_samples):\n",
    "    \"\"\"generate random data.\n",
    "    The first level defines the baseline that holds for all random numbers\n",
    "    \n",
    "    Inputs:\n",
    "    * n_samples: number of samples\n",
    "    * contributer_coefficients: dictionary with (mean,sig) per level per contributer\n",
    "    \n",
    "    Outputs:\n",
    "    * data: array with the final number\n",
    "    * contributers: matrix defining the contributers, first column is for the first level\"\"\"\n",
    "    \n",
    "    assert len(contributer_coefficients[0]) == 1, \"Level 0 defines the baseline. It should have exactly one contributer\"\n",
    "    #data = np.random.normal(gen_avg, gen_sig, n_samples)\n",
    "    data = np.zeros((n_samples, ))\n",
    "    contributers = np.zeros((n_samples, len(contributer_coefficients)))\n",
    "    for lvl, cdict in enumerate(contributer_coefficients):\n",
    "        #print(f\"creating level {lvl}\")\n",
    "        lvl_influencers = len(cdict) #number of influencers in this level\n",
    "        lvldata = np.zeros((n_samples, lvl_influencers))\n",
    "\n",
    "        for i, (mu,sig) in cdict.items():\n",
    "            lvldata[:,i] = np.random.normal(mu, sig, n_samples)\n",
    "\n",
    "        selection = np.random.randint(low=0,\n",
    "                                    high=lvl_influencers,\n",
    "                                    size=(n_samples))\n",
    "        contributers[:, lvl] = selection\n",
    "        \n",
    "        data += np.array([lvldata[row, col] for row, col in enumerate(selection)])\n",
    "        # Note: The first level \n",
    "    return data, contributers[:, 1:].astype(int)\n",
    "\n",
    "def generate(n_samples, contributer_coefficients):\n",
    "    if contributer_coefficients == 2:\n",
    "        n_contributers= len(contributer_coefficients[1])\n",
    "        print(\"ATTENTION: just for one level\")\n",
    "    else:\n",
    "        n_contributers = [len(level) for level in contributer_coefficients][1:]\n",
    "\n",
    "    print(\"generating Data for\")\n",
    "    print_coefficients(contributer_coefficients)\n",
    "\n",
    "    data, contributers = gen_data(n_samples=n_samples,\n",
    "                              contributer_coefficients=contributer_coefficients)\n",
    "\n",
    "    #contributers = contributers.squeeze(-1) # kill the first level - not needed\n",
    "    return data, contributers, n_contributers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generating Data for\n",
      "Stage 0: Contributer 0 mu=0.00, sig=5.00\n",
      "Stage 1: Contributer 0 mu=2.00, sig=1.00\n",
      "Stage 1: Contributer 1 mu=-1.00, sig=1.00\n",
      "Stage 1: Contributer 2 mu=-1.00, sig=3.00\n",
      "Stage 2: Contributer 0 mu=2.00, sig=1.00\n",
      "Stage 2: Contributer 1 mu=-1.00, sig=1.00\n",
      "Stage 2: Contributer 2 mu=-1.00, sig=1.00\n",
      "Stage 2: Contributer 3 mu=0.00, sig=1.00\n"
     ]
    }
   ],
   "source": [
    "n_samples = 10000\n",
    "\n",
    "cc_27 = [\n",
    "    {    0 : (2, 5)},\n",
    "    {    0: (2, 1),\n",
    "        1: (-1, 1),\n",
    "        2: (-1, 1)},\n",
    "    {    0: (3, 1),\n",
    "        1: (-1, 1),\n",
    "        2: (-1, 1),\n",
    "        3: (-1, 1)}\n",
    "        ]\n",
    "\n",
    "cc_27b = [\n",
    "    {    0 : (2, 5)},\n",
    "    {    0: (2, 1),\n",
    "        1: (-1, 1),\n",
    "        2: (-1, 3)},\n",
    "    {    0: (2, 1),\n",
    "        1: (-1, 1),\n",
    "        2: (-1, 1),\n",
    "        3: (0, 1)}\n",
    "        ]\n",
    "\n",
    "data, contributers, n_contributers = generate(n_samples, contributer_coefficients=cc_27b)\n",
    "\n",
    "enc = OneHotEncoder(handle_unknown='ignore')\n",
    "enc.fit(contributers)\n",
    "contributers_ohe = enc.transform(contributers).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval(regressor, n_contributers=n_contributers):\n",
    "    \"\"\"print intercept and coefficients\"\"\"\n",
    "    print(f\"Intercept: {regressor.intercept_}\")\n",
    "    l = list(regressor.coef_)\n",
    "    p = lambda i: [l.pop(0) for _ in range(i)]\n",
    "    for i,n in enumerate(n_contributers):\n",
    "        print(f\"{i}: {p(n)}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [Ridge Regression](https://scikit-learn.org/stable/modules/linear_model.html#regression)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intercept: 0.0\n",
      "0: [3.097302050817801, 0.04766634459597961, 0.26073853568382976]\n",
      "1: [2.954364252644228, -0.07923289135828614, -0.3578894019992378, 0.8884649718152803]\n"
     ]
    }
   ],
   "source": [
    "reg = linear_model.Ridge(alpha=1, fit_intercept=False)\n",
    "reg.fit(contributers_ohe, data)\n",
    "eval(reg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "Magnitude of the estimated coefficients sometimes fits, the sign does not\n",
    "# [Lasso](https://scikit-learn.org/stable/modules/linear_model.html#lasso)\n",
    "--> [LassoLarsCV](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LassoLarsCV.html#sklearn.linear_model.LassoLarsCV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intercept: 0.45856503635063905\n",
      "0: [2.837431104774484, -0.21314387213902017, 0.0]\n",
      "1: [2.757450471040065, -0.2773614829134523, -0.5561259387303802, 0.6907534127347048]\n"
     ]
    }
   ],
   "source": [
    "reg = linear_model.LassoLarsCV(cv=5).fit(contributers_ohe, data)\n",
    "reg.score(contributers_ohe, data)\n",
    "eval(reg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [Elastic-Net](https://scikit-learn.org/stable/modules/linear_model.html#elastic-net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intercept: 1.631752576828788\n",
      "0: [2.304240152859488, -0.7363586094433596, -0.5237140689177535]\n",
      "1: [2.103001090198751, -0.9188301162845305, -1.1969318466149743, 0.041339111601008345]\n"
     ]
    }
   ],
   "source": [
    "reg = linear_model.ElasticNetCV(cv=5).fit(contributers_ohe, data)\n",
    "eval(reg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [LARS-Lasso](https://scikit-learn.org/stable/modules/linear_model.html#lars-lasso)\n",
    "--> finds biggest contributers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intercept: 0.6310597851849238\n",
      "0: [2.4769130156925088, 0.0, 0.0]\n",
      "1: [2.2337632301961667, 0.0, -0.28022853369218503, 0.14918580267530482]\n"
     ]
    }
   ],
   "source": [
    "reg = linear_model.LassoLars(alpha=0.1).fit(contributers_ohe, data)\n",
    "eval(reg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [Orthogonal Matching Pursuit](https://scikit-learn.org/stable/modules/linear_model.html#orthogonal-matching-pursuit-omp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intercept: 1.01284633963874\n",
      "0: [2.9225102342995055, 0.0, 0.0]\n",
      "1: [0.0, 0.0, 0.0, 0.0]\n"
     ]
    }
   ],
   "source": [
    "reg = linear_model.OrthogonalMatchingPursuit().fit(contributers_ohe, data)\n",
    "eval(reg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [Bayesian Ridge Regression](https://scikit-learn.org/stable/modules/linear_model.html#bayesian-ridge-regression)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intercept: 1.9869654053273471\n",
      "0: [1.9557167629006482, -1.0840400308455844, -0.8716767320490477]\n",
      "1: [2.0940611945347807, -0.9266376291178181, -1.2041547983416072, 0.03673123292333058]\n",
      "precision of the noise:0.03428529358321994\n",
      "Estimated precision of the weights: 0.3997707714213595\n",
      "stimated variance-covariance matrix of the weights: [[ 8.39661586e-01  8.30904004e-01  8.30867911e-01  7.55590649e-06\n",
      "  -8.60946973e-05 -5.69608620e-05  1.35499653e-04]\n",
      " [ 8.30904004e-01  8.39590610e-01  8.30938886e-01 -2.04927474e-05\n",
      "   5.85937463e-05  7.32765492e-05 -1.11377548e-04]\n",
      " [ 8.30867911e-01  8.30938886e-01  8.39626703e-01  1.29368409e-05\n",
      "   2.75009510e-05 -1.63156872e-05 -2.41221047e-05]\n",
      " [ 7.55590649e-06 -2.04927474e-05  1.29368409e-05  6.34026951e-01\n",
      "   6.22489834e-01  6.22494332e-01  6.22422383e-01]\n",
      " [-8.60946973e-05  5.85937463e-05  2.75009510e-05  6.22489834e-01\n",
      "   6.34041908e-01  6.22488728e-01  6.22413030e-01]\n",
      " [-5.69608620e-05  7.32765492e-05 -1.63156872e-05  6.22494332e-01\n",
      "   6.22488728e-01  6.34032460e-01  6.22417981e-01]\n",
      " [ 1.35499653e-04 -1.11377548e-04 -2.41221047e-05  6.22422383e-01\n",
      "   6.22413030e-01  6.22417981e-01  6.34180106e-01]]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "reg = linear_model.BayesianRidge().fit(contributers_ohe, data)\n",
    "eval(reg)\n",
    "\n",
    "print(f\"precision of the noise:{reg.alpha_}\")\n",
    "print(f\"Estimated precision of the weights: {reg.lambda_}\")\n",
    "print(f\"stimated variance-covariance matrix of the weights: {reg.sigma_}\")\n",
    "print(f\"\")\n",
    "print(f\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [Auomatic Relevance Determination](https://scikit-learn.org/stable/modules/linear_model.html#automatic-relevance-determination-ard)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intercept: 1.0854079282631273\n",
      "0: [2.87493700896671, -0.13194958858388103, 0.0034860958933150667]\n",
      "1: [2.084006595408319, -0.9328661746751291, -1.2140800762437054, 0.00622032983995785]\n"
     ]
    }
   ],
   "source": [
    "reg = linear_model.ARDRegression().fit(contributers_ohe, data)\n",
    "eval(reg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
