{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Number Decomposition\n",
    "Idea: Decompose the sum of random numbers into its contributions\n",
    "\n",
    "for a given set of $x_i$ and $a_{ik}$ with\n",
    "$$x_i = \\Sigma_{j=0}^n \\Sigma_{k=1}^{m_j} a_{ik}y_{k}$$ \n",
    "with\n",
    "* $m_0 = 1$\n",
    "* $m_j$ the number of contributers per layer\n",
    "* $a_{ik} \\in \\{0, 1\\}$\n",
    "* $\\Sigma a_{ik} = 1$ \n",
    "\n",
    "calculate the Distributions $a_{ik} \\sim N(μ_{l}, σ_{l})$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m\u001b[1m  Activating\u001b[22m\u001b[39m project at `d:\\Code\\ProbabilisticProgramming`\n"
     ]
    }
   ],
   "source": [
    "using Pkg\n",
    "Pkg.activate(\".\")\n",
    "#Pkg.add(\"Turing\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "using Turing, Distributions, Statistics, Distributed, Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3-element Vector{Dict{Int64, Tuple{Int64, Int64}}}:\n",
       " Dict(1 => (0, 5))\n",
       " Dict(4 => (4, 1), 2 => (2, 1), 3 => (3, 2), 1 => (1, 1))\n",
       " Dict(5 => (5, 1), 4 => (4, 1), 2 => (2, 1), 3 => (3, 2), 1 => (1, 1))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cc_12 = [\n",
    "    Dict( 1 => (0, 5)),\n",
    "    Dict( \n",
    "        1 => (1, 1),\n",
    "        2 => (2, 1),\n",
    "        ),\n",
    "]\n",
    "cc_14 = [\n",
    "    Dict( 1 => (0, 5)),\n",
    "    Dict( \n",
    "        1 => (1, 1),\n",
    "        2 => (2, 1),\n",
    "        3 => (3, 2),\n",
    "        4 => (4, 1)\n",
    "        ),\n",
    "]\n",
    "cc_29 = [\n",
    "    Dict( 1 => (0, 5)),\n",
    "    Dict( \n",
    "        1 => (1, 1),\n",
    "        2 => (2, 1),\n",
    "        3 => (3, 2),\n",
    "        4 => (4, 1)\n",
    "        ),\n",
    "    Dict( \n",
    "        1 => (1, 1),\n",
    "        2 => (2, 1),\n",
    "        3 => (3, 2),\n",
    "        4 => (4, 1),\n",
    "        5 => (5, 1)\n",
    "        ),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "generate_data"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\"\"\"align coefficients to have a mean of 0 for every layer\"\"\"\n",
    "function align_coefficients(coefficients)\n",
    "    @assert (length(coefficients[1]) == 1) \"first level is just allowed to have one contributer\"\n",
    "    coefs2 = []\n",
    "    for layer in coefficients\n",
    "        means = [m for (k, (m, v)) in layer]\n",
    "        m0 = mean(means)\n",
    "        # adjust the means\n",
    "        append!(coefs2, [Dict(k=> (m - m0, v) for (k, (m, v)) in layer)]) #every element from the list will be added => [Dict()]\n",
    "    end\n",
    "    coefs2\n",
    "end\n",
    "@test_throws AssertionError begin\n",
    "    cc = [ Dict( 1 => (0, 5), 2 => (3, 4))]\n",
    "    align_coefficients(cc)\n",
    "end\n",
    "@test begin\n",
    "    cc = [\n",
    "    Dict( 1 => (2, 5)),\n",
    "    Dict( \n",
    "        1 => (1, 1),\n",
    "        2 => (2, 1),\n",
    "        3 => (3, 2),\n",
    "        ),\n",
    "]\n",
    "    align_coefficients(cc) == [Dict(1 => (0.0, 5))\n",
    "    Dict(2 => (0.0, 1), 3 => (1.0, 2), 1 => (-1.0, 1))]\n",
    "end\n",
    "\n",
    "\"\"\"create random numbers out of a set of coefficients\"\"\"\n",
    "function generate_data(coefficients, n_samples)\n",
    "    @assert n_samples > 0\n",
    "    coefficients = align_coefficients(coefficients)\n",
    "    data = Vector{Float16}(undef, n_samples)\n",
    "    data .= 0\n",
    "\n",
    "    contributers = []\n",
    "    for layer in coefficients\n",
    "        max_con = maximum(collect(keys(layer)))\n",
    "        cons = rand(1:max_con, n_samples)\n",
    "        for (con, (mu, sigma)) in layer\n",
    "            rows = cons.== con\n",
    "            n_rows = sum(rows)\n",
    "            N = Normal(mu, sigma)\n",
    "            data[rows] += rand(N, n_rows)\n",
    "        end\n",
    "        append!(contributers, [cons])\n",
    "\n",
    "    end\n",
    "    popfirst!(contributers) # first set has by default just one contributer\n",
    "    data, contributers\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Float16[3.023, -7.6, 4.52, 1.509, 2.234, -0.3215, -10.53, 1.698, -5.34, 1.77  …  3.629, 1.803, 0.1256, 5.312, -4.156, 5.883, -2.285, 4.9, 4.21, 1.487], Any[[4, 2, 1, 3, 4, 3, 4, 3, 2, 1  …  1, 3, 1, 3, 3, 2, 2, 4, 4, 2]])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data, contributers = generate_data(cc_01, 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "model_fun7 (generic function with 2 methods)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "@model function model_fun3(data, contributers)\n",
    "    n_contributers = maximum(contributers)\n",
    "    sigmax = var(data)\n",
    "    max_con = 5 #Maximum expected value for contributers\n",
    "    μ_a ~ Normal( 0, 10) \n",
    "    sigma ~ Uniform(0, sigmax)\n",
    "\n",
    "    μ_cons = Vector{Float16}(undef, n_contributers)\n",
    "\n",
    "    cons = Vector{Float16}(undef, n_contributers)\n",
    "\n",
    "    for i in 1:(n_contributers-1)\n",
    "        μ_cons[i] ~ Uniform(0, max_con)\n",
    "        cons[i] ~ Normal(μ_cons[i], sigmax)\n",
    "    end\n",
    "    μ_cons[n_contributers] ~ Uniform(0, max_con)\n",
    "    cons[n_contributers] ~ Normal(-sum(μ_cons[1:(n_contributers-1)]), sigmax) #normalization\n",
    "    \n",
    "\n",
    "    for con = 1:n_contributers\n",
    "        rows = contributers .== con\n",
    "        data[rows] .~ Normal(μ_a + cons[con], sigma)\n",
    "    end\n",
    "end # Works :-D\n",
    "\n",
    "@model function model_fun4(data, contributers)\n",
    "    n_contributers = maximum(contributers)\n",
    "    sigmax = var(data)\n",
    "    max_con = 5 #Maximum expected value for contributers\n",
    "    μ_a ~ Normal( 0, 10) \n",
    "    sigma ~ Uniform(0, sigmax)\n",
    "\n",
    "    μ_cons = Vector{Float16}(undef, n_contributers)\n",
    "\n",
    "    cons = Vector{Float16}(undef, n_contributers)\n",
    "\n",
    "    for i in 1:(n_contributers-1)\n",
    "        μ_cons[i] ~ Uniform(0, max_con)\n",
    "        cons[i] ~ Normal(μ_cons[i], sigmax)\n",
    "    end\n",
    "    μ_cons[n_contributers] ~ Uniform(0, max_con)\n",
    "    cons[n_contributers] ~ Normal(-sum(μ_cons[1:(n_contributers-1)]), sigmax) #normalization\n",
    "    \n",
    "    m = Vector{Float16}(undef, length(data))\n",
    "    m .= μ_a\n",
    "\n",
    "    for con = 1:n_contributers\n",
    "        rows = contributers .== con\n",
    "        m[rows] .+= cons[con]\n",
    "        #data[rows] .~ Normal(μ_a + cons[con], sigma)\n",
    "    end\n",
    "    for i=1:length(data)\n",
    "        data[i] ~ Normal(m[i], sigma)\n",
    "    end\n",
    "end # DOES NOT WORK\n",
    "\n",
    "@model function model_fun5(data, contributers)\n",
    "    n_contributers = maximum(contributers)\n",
    "    sigmax = var(data)\n",
    "    max_con = 5 #Maximum expected value for contributers\n",
    "    μ_a ~ Normal( 0, 10) \n",
    "    sigma ~ Uniform(0, sigmax)\n",
    "\n",
    "    μ_cons = Vector{Float16}(undef, n_contributers)\n",
    "\n",
    "    cons = Vector{Float16}(undef, n_contributers)\n",
    "\n",
    "    for i in 1:(n_contributers-1)\n",
    "        μ_cons[i] ~ Uniform(0, max_con)\n",
    "        cons[i] ~ Normal(μ_cons[i], sigmax)\n",
    "    end\n",
    "    μ_cons[n_contributers] ~ Uniform(0, max_con)\n",
    "    cons[n_contributers] ~ Normal(-sum(μ_cons[1:(n_contributers-1)]), sigmax) #normalization\n",
    "\n",
    "    for i in eachindex(data)\n",
    "        data[i] ~ Normal(μ_a + cons[contributers[i]], sigma)\n",
    "    end\n",
    "end #works\n",
    "\n",
    "@model function model_fun6(data, contributers)\n",
    "    n_contributers = maximum(contributers)\n",
    "    sigmax = var(data)\n",
    "    max_con = 5 #Maximum expected value for contributers\n",
    "    μ_a ~ Normal( 0, 10) \n",
    "    sigma ~ Uniform(0, sigmax)\n",
    "\n",
    "    cons = Vector{Float16}(undef, n_contributers)\n",
    "\n",
    "    for i in eachindex(cons)\n",
    "        cons[i] ~ Normal(0, sigmax)\n",
    "    end\n",
    "\n",
    "    for i in eachindex(data)\n",
    "        data[i] ~ Normal(μ_a + cons[contributers[i]], sigma)\n",
    "    end\n",
    "end #works\n",
    "\n",
    "@model function model_fun7(data, contributers)\n",
    "    n_contributers = maximum(contributers)\n",
    "    sigmax = var(data)\n",
    "    max_con = 5 #Maximum expected value for contributers\n",
    "    μ_a ~ Normal( 0, 10) \n",
    "    sigma ~ Uniform(0, sigmax)\n",
    "\n",
    "    μ_cons = Vector{Float16}(undef, n_contributers)\n",
    "    σ_cons = Vector{Float16}(undef, n_contributers)\n",
    "\n",
    "    cons = Vector{Float16}(undef, n_contributers)\n",
    "\n",
    "    for i in 1:(n_contributers-1)\n",
    "        μ_cons[i] ~ Uniform(0, max_con)\n",
    "        σ_cons[i] ~ Uniform(0, sigmax)\n",
    "        cons[i] ~ Normal(μ_cons[i], σ_cons[i] )\n",
    "    end\n",
    "    μ_cons[n_contributers] ~ Uniform(0, max_con)\n",
    "    σ_cons[n_contributers] ~ Uniform(0, sigmax)\n",
    "    cons[n_contributers] ~ Normal(-sum(μ_cons[1:(n_contributers-1)]), σ_cons[n_contributers]) #normalization\n",
    "\n",
    "    for i in eachindex(data)\n",
    "        data[i] ~ Normal(μ_a + cons[contributers[i]], sigma)\n",
    "    end\n",
    "end #works\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mSampling   0%|█                                         |  ETA: N/A\u001b[39m\n",
      "┌ Info: Found initial step size\n",
      "│   ϵ = 0.2\n",
      "└ @ Turing.Inference C:\\Users\\fuerf\\.julia\\packages\\Turing\\QN7BL\\src\\mcmc\\hmc.jl:212\n",
      "\u001b[32mSampling   0%|█                                         |  ETA: 0:01:29\u001b[39m\n",
      "\u001b[32mSampling   1%|█                                         |  ETA: 0:01:38\u001b[39m\n",
      "\u001b[32mSampling   2%|█                                         |  ETA: 0:01:26\u001b[39m\n",
      "\u001b[32mSampling   2%|█                                         |  ETA: 0:01:24\u001b[39m\n",
      "\u001b[32mSampling   2%|██                                        |  ETA: 0:01:20\u001b[39m\n",
      "\u001b[32mSampling   3%|██                                        |  ETA: 0:01:14\u001b[39m\n",
      "\u001b[32mSampling   4%|██                                        |  ETA: 0:01:09\u001b[39m\n",
      "\u001b[32mSampling   4%|██                                        |  ETA: 0:01:06\u001b[39m\n",
      "\u001b[32mSampling   4%|██                                        |  ETA: 0:01:05\u001b[39m\n",
      "\u001b[32mSampling   5%|███                                       |  ETA: 0:01:04\u001b[39m\n",
      "\u001b[32mSampling   6%|███                                       |  ETA: 0:01:03\u001b[39m\n",
      "\u001b[32mSampling   6%|███                                       |  ETA: 0:01:02\u001b[39m\n",
      "\u001b[32mSampling   6%|███                                       |  ETA: 0:01:01\u001b[39m\n",
      "\u001b[32mSampling   7%|███                                       |  ETA: 0:00:59\u001b[39m\n",
      "\u001b[32mSampling   8%|████                                      |  ETA: 0:00:58\u001b[39m\n",
      "\u001b[32mSampling   8%|████                                      |  ETA: 0:00:56\u001b[39m\n",
      "\u001b[32mSampling   8%|████                                      |  ETA: 0:00:56\u001b[39m\n",
      "\u001b[32mSampling   9%|████                                      |  ETA: 0:00:55\u001b[39m\n",
      "\u001b[32mSampling  10%|████                                      |  ETA: 0:00:55\u001b[39m\n",
      "\u001b[32mSampling  10%|█████                                     |  ETA: 0:00:55\u001b[39m\n",
      "\u001b[32mSampling  10%|█████                                     |  ETA: 0:00:54\u001b[39m\n",
      "\u001b[32mSampling  11%|█████                                     |  ETA: 0:00:54\u001b[39m\n",
      "\u001b[32mSampling  12%|█████                                     |  ETA: 0:00:53\u001b[39m\n",
      "\u001b[32mSampling  12%|██████                                    |  ETA: 0:00:53\u001b[39m\n",
      "\u001b[32mSampling  12%|██████                                    |  ETA: 0:00:52\u001b[39m\n",
      "\u001b[32mSampling  13%|██████                                    |  ETA: 0:00:52\u001b[39m\n",
      "\u001b[32mSampling  14%|██████                                    |  ETA: 0:00:52\u001b[39m\n",
      "\u001b[32mSampling  14%|██████                                    |  ETA: 0:00:51\u001b[39m\n",
      "\u001b[32mSampling  14%|███████                                   |  ETA: 0:00:51\u001b[39m\n",
      "\u001b[32mSampling  15%|███████                                   |  ETA: 0:00:50\u001b[39m\n",
      "\u001b[32mSampling  16%|███████                                   |  ETA: 0:00:50\u001b[39m\n",
      "\u001b[32mSampling  16%|███████                                   |  ETA: 0:00:50\u001b[39m\n",
      "\u001b[32mSampling  16%|███████                                   |  ETA: 0:00:50\u001b[39m\n",
      "\u001b[32mSampling  17%|████████                                  |  ETA: 0:00:49\u001b[39m\n",
      "\u001b[32mSampling  18%|████████                                  |  ETA: 0:00:49\u001b[39m\n",
      "\u001b[32mSampling  18%|████████                                  |  ETA: 0:00:49\u001b[39m\n",
      "\u001b[32mSampling  18%|████████                                  |  ETA: 0:00:48\u001b[39m\n",
      "\u001b[32mSampling  19%|████████                                  |  ETA: 0:00:48\u001b[39m\n",
      "\u001b[32mSampling  20%|█████████                                 |  ETA: 0:00:48\u001b[39m\n",
      "\u001b[32mSampling  20%|█████████                                 |  ETA: 0:00:48\u001b[39m\n",
      "\u001b[32mSampling  20%|█████████                                 |  ETA: 0:00:47\u001b[39m\n",
      "\u001b[32mSampling  21%|█████████                                 |  ETA: 0:00:47\u001b[39m\n",
      "\u001b[32mSampling  22%|██████████                                |  ETA: 0:00:47\u001b[39m\n",
      "\u001b[32mSampling  22%|██████████                                |  ETA: 0:00:47\u001b[39m\n",
      "\u001b[32mSampling  22%|██████████                                |  ETA: 0:00:46\u001b[39m\n",
      "\u001b[32mSampling  23%|██████████                                |  ETA: 0:00:46\u001b[39m\n",
      "\u001b[32mSampling  24%|██████████                                |  ETA: 0:00:46\u001b[39m\n",
      "\u001b[32mSampling  24%|███████████                               |  ETA: 0:00:45\u001b[39m\n",
      "\u001b[32mSampling  24%|███████████                               |  ETA: 0:00:45\u001b[39m\n",
      "\u001b[32mSampling  25%|███████████                               |  ETA: 0:00:45\u001b[39m\n",
      "\u001b[32mSampling  26%|███████████                               |  ETA: 0:00:44\u001b[39m\n",
      "\u001b[32mSampling  26%|███████████                               |  ETA: 0:00:44\u001b[39m\n",
      "\u001b[32mSampling  26%|████████████                              |  ETA: 0:00:44\u001b[39m\n",
      "\u001b[32mSampling  27%|████████████                              |  ETA: 0:00:44\u001b[39m\n",
      "\u001b[32mSampling  28%|████████████                              |  ETA: 0:00:43\u001b[39m\n",
      "\u001b[32mSampling  28%|████████████                              |  ETA: 0:00:43\u001b[39m\n",
      "\u001b[32mSampling  28%|████████████                              |  ETA: 0:00:43\u001b[39m\n",
      "\u001b[32mSampling  29%|█████████████                             |  ETA: 0:00:42\u001b[39m\n",
      "\u001b[32mSampling  30%|█████████████                             |  ETA: 0:00:42\u001b[39m\n",
      "\u001b[32mSampling  30%|█████████████                             |  ETA: 0:00:42\u001b[39m\n",
      "\u001b[32mSampling  30%|█████████████                             |  ETA: 0:00:42\u001b[39m\n",
      "\u001b[32mSampling  31%|██████████████                            |  ETA: 0:00:41\u001b[39m\n",
      "\u001b[32mSampling  32%|██████████████                            |  ETA: 0:00:41\u001b[39m\n",
      "\u001b[32mSampling  32%|██████████████                            |  ETA: 0:00:41\u001b[39m\n",
      "\u001b[32mSampling  32%|██████████████                            |  ETA: 0:00:41\u001b[39m\n",
      "\u001b[32mSampling  33%|██████████████                            |  ETA: 0:00:40\u001b[39m\n",
      "\u001b[32mSampling  34%|███████████████                           |  ETA: 0:00:40\u001b[39m\n",
      "\u001b[32mSampling  34%|███████████████                           |  ETA: 0:00:40\u001b[39m\n",
      "\u001b[32mSampling  34%|███████████████                           |  ETA: 0:00:39\u001b[39m\n",
      "\u001b[32mSampling  35%|███████████████                           |  ETA: 0:00:39\u001b[39m\n",
      "\u001b[32mSampling  36%|███████████████                           |  ETA: 0:00:39\u001b[39m\n",
      "\u001b[32mSampling  36%|████████████████                          |  ETA: 0:00:39\u001b[39m\n",
      "\u001b[32mSampling  36%|████████████████                          |  ETA: 0:00:38\u001b[39m\n",
      "\u001b[32mSampling  37%|████████████████                          |  ETA: 0:00:38\u001b[39m\n",
      "\u001b[32mSampling  38%|████████████████                          |  ETA: 0:00:38\u001b[39m\n",
      "\u001b[32mSampling  38%|████████████████                          |  ETA: 0:00:37\u001b[39m\n",
      "\u001b[32mSampling  38%|█████████████████                         |  ETA: 0:00:37\u001b[39m\n",
      "\u001b[32mSampling  39%|█████████████████                         |  ETA: 0:00:37\u001b[39m\n",
      "\u001b[32mSampling  40%|█████████████████                         |  ETA: 0:00:37\u001b[39m\n",
      "\u001b[32mSampling  40%|█████████████████                         |  ETA: 0:00:36\u001b[39m\n",
      "\u001b[32mSampling  40%|██████████████████                        |  ETA: 0:00:36\u001b[39m\n",
      "\u001b[32mSampling  41%|██████████████████                        |  ETA: 0:00:36\u001b[39m\n",
      "\u001b[32mSampling  42%|██████████████████                        |  ETA: 0:00:36\u001b[39m\n",
      "\u001b[32mSampling  42%|██████████████████                        |  ETA: 0:00:35\u001b[39m\n",
      "\u001b[32mSampling  42%|██████████████████                        |  ETA: 0:00:35\u001b[39m\n",
      "\u001b[32mSampling  43%|███████████████████                       |  ETA: 0:00:35\u001b[39m\n",
      "\u001b[32mSampling  44%|███████████████████                       |  ETA: 0:00:34\u001b[39m\n",
      "\u001b[32mSampling  44%|███████████████████                       |  ETA: 0:00:34\u001b[39m\n",
      "\u001b[32mSampling  44%|███████████████████                       |  ETA: 0:00:34\u001b[39m\n",
      "\u001b[32mSampling  45%|███████████████████                       |  ETA: 0:00:33\u001b[39m\n",
      "\u001b[32mSampling  46%|████████████████████                      |  ETA: 0:00:33\u001b[39m\n",
      "\u001b[32mSampling  46%|████████████████████                      |  ETA: 0:00:33\u001b[39m\n",
      "\u001b[32mSampling  46%|████████████████████                      |  ETA: 0:00:33\u001b[39m\n",
      "\u001b[32mSampling  47%|████████████████████                      |  ETA: 0:00:32\u001b[39m\n",
      "\u001b[32mSampling  48%|████████████████████                      |  ETA: 0:00:32\u001b[39m\n",
      "\u001b[32mSampling  48%|█████████████████████                     |  ETA: 0:00:32\u001b[39m\n",
      "\u001b[32mSampling  48%|█████████████████████                     |  ETA: 0:00:31\u001b[39m\n",
      "\u001b[32mSampling  49%|█████████████████████                     |  ETA: 0:00:31\u001b[39m\n",
      "\u001b[32mSampling  50%|█████████████████████                     |  ETA: 0:00:30\u001b[39m\n",
      "\u001b[32mSampling  50%|██████████████████████                    |  ETA: 0:00:30\u001b[39m\n",
      "\u001b[32mSampling  50%|██████████████████████                    |  ETA: 0:00:30\u001b[39m\n",
      "\u001b[32mSampling  51%|██████████████████████                    |  ETA: 0:00:29\u001b[39m\n",
      "\u001b[32mSampling  52%|██████████████████████                    |  ETA: 0:00:29\u001b[39m\n",
      "\u001b[32mSampling  52%|██████████████████████                    |  ETA: 0:00:29\u001b[39m\n",
      "\u001b[32mSampling  52%|███████████████████████                   |  ETA: 0:00:29\u001b[39m\n",
      "\u001b[32mSampling  53%|███████████████████████                   |  ETA: 0:00:28\u001b[39m\n",
      "\u001b[32mSampling  54%|███████████████████████                   |  ETA: 0:00:28\u001b[39m\n",
      "\u001b[32mSampling  54%|███████████████████████                   |  ETA: 0:00:28\u001b[39m\n",
      "\u001b[32mSampling  55%|███████████████████████                   |  ETA: 0:00:27\u001b[39m\n",
      "\u001b[32mSampling  55%|████████████████████████                  |  ETA: 0:00:27\u001b[39m\n",
      "\u001b[32mSampling  56%|████████████████████████                  |  ETA: 0:00:27\u001b[39m\n",
      "\u001b[32mSampling  56%|████████████████████████                  |  ETA: 0:00:26\u001b[39m\n",
      "\u001b[32mSampling  56%|████████████████████████                  |  ETA: 0:00:26\u001b[39m\n",
      "\u001b[32mSampling  57%|████████████████████████                  |  ETA: 0:00:26\u001b[39m\n",
      "\u001b[32mSampling  57%|█████████████████████████                 |  ETA: 0:00:26\u001b[39m\n",
      "\u001b[32mSampling  58%|█████████████████████████                 |  ETA: 0:00:25\u001b[39m\n",
      "\u001b[32mSampling  58%|█████████████████████████                 |  ETA: 0:00:25\u001b[39m\n",
      "\u001b[32mSampling  59%|█████████████████████████                 |  ETA: 0:00:25\u001b[39m\n",
      "\u001b[32mSampling  60%|█████████████████████████                 |  ETA: 0:00:24\u001b[39m\n",
      "\u001b[32mSampling  60%|██████████████████████████                |  ETA: 0:00:24\u001b[39m\n",
      "\u001b[32mSampling  60%|██████████████████████████                |  ETA: 0:00:24\u001b[39m\n",
      "\u001b[32mSampling  61%|██████████████████████████                |  ETA: 0:00:23\u001b[39m\n",
      "\u001b[32mSampling  62%|██████████████████████████                |  ETA: 0:00:23\u001b[39m\n",
      "\u001b[32mSampling  62%|███████████████████████████               |  ETA: 0:00:23\u001b[39m\n",
      "\u001b[32mSampling  62%|███████████████████████████               |  ETA: 0:00:23\u001b[39m\n",
      "\u001b[32mSampling  63%|███████████████████████████               |  ETA: 0:00:22\u001b[39m\n",
      "\u001b[32mSampling  64%|███████████████████████████               |  ETA: 0:00:22\u001b[39m\n",
      "\u001b[32mSampling  64%|███████████████████████████               |  ETA: 0:00:22\u001b[39m\n",
      "\u001b[32mSampling  64%|████████████████████████████              |  ETA: 0:00:21\u001b[39m\n",
      "\u001b[32mSampling  65%|████████████████████████████              |  ETA: 0:00:21\u001b[39m\n",
      "\u001b[32mSampling  66%|████████████████████████████              |  ETA: 0:00:21\u001b[39m\n",
      "\u001b[32mSampling  66%|████████████████████████████              |  ETA: 0:00:20\u001b[39m\n",
      "\u001b[32mSampling  66%|████████████████████████████              |  ETA: 0:00:20\u001b[39m\n",
      "\u001b[32mSampling  67%|█████████████████████████████             |  ETA: 0:00:20\u001b[39m\n",
      "\u001b[32mSampling  68%|█████████████████████████████             |  ETA: 0:00:20\u001b[39m\n",
      "\u001b[32mSampling  68%|█████████████████████████████             |  ETA: 0:00:19\u001b[39m\n",
      "\u001b[32mSampling  68%|█████████████████████████████             |  ETA: 0:00:19\u001b[39m\n",
      "\u001b[32mSampling  69%|█████████████████████████████             |  ETA: 0:00:19\u001b[39m\n",
      "\u001b[32mSampling  70%|██████████████████████████████            |  ETA: 0:00:18\u001b[39m\n",
      "\u001b[32mSampling  70%|██████████████████████████████            |  ETA: 0:00:18\u001b[39m\n",
      "\u001b[32mSampling  70%|██████████████████████████████            |  ETA: 0:00:18\u001b[39m\n",
      "\u001b[32mSampling  71%|██████████████████████████████            |  ETA: 0:00:18\u001b[39m\n",
      "\u001b[32mSampling  72%|███████████████████████████████           |  ETA: 0:00:17\u001b[39m\n",
      "\u001b[32mSampling  72%|███████████████████████████████           |  ETA: 0:00:17\u001b[39m\n",
      "\u001b[32mSampling  72%|███████████████████████████████           |  ETA: 0:00:17\u001b[39m\n",
      "\u001b[32mSampling  73%|███████████████████████████████           |  ETA: 0:00:16\u001b[39m\n",
      "\u001b[32mSampling  74%|███████████████████████████████           |  ETA: 0:00:16\u001b[39m\n",
      "\u001b[32mSampling  74%|████████████████████████████████          |  ETA: 0:00:16\u001b[39m\n",
      "\u001b[32mSampling  74%|████████████████████████████████          |  ETA: 0:00:15\u001b[39m\n",
      "\u001b[32mSampling  75%|████████████████████████████████          |  ETA: 0:00:15\u001b[39m\n",
      "\u001b[32mSampling  76%|████████████████████████████████          |  ETA: 0:00:15\u001b[39m\n",
      "\u001b[32mSampling  76%|████████████████████████████████          |  ETA: 0:00:15\u001b[39m\n",
      "\u001b[32mSampling  76%|█████████████████████████████████         |  ETA: 0:00:14\u001b[39m\n",
      "\u001b[32mSampling  77%|█████████████████████████████████         |  ETA: 0:00:14\u001b[39m\n",
      "\u001b[32mSampling  78%|█████████████████████████████████         |  ETA: 0:00:14\u001b[39m\n",
      "\u001b[32mSampling  78%|█████████████████████████████████         |  ETA: 0:00:13\u001b[39m\n",
      "\u001b[32mSampling  78%|█████████████████████████████████         |  ETA: 0:00:13\u001b[39m\n",
      "\u001b[32mSampling  79%|██████████████████████████████████        |  ETA: 0:00:13\u001b[39m\n",
      "\u001b[32mSampling  80%|██████████████████████████████████        |  ETA: 0:00:12\u001b[39m\n",
      "\u001b[32mSampling  80%|██████████████████████████████████        |  ETA: 0:00:12\u001b[39m\n",
      "\u001b[32mSampling  80%|██████████████████████████████████        |  ETA: 0:00:12\u001b[39m\n",
      "\u001b[32mSampling  81%|███████████████████████████████████       |  ETA: 0:00:11\u001b[39m\n",
      "\u001b[32mSampling  82%|███████████████████████████████████       |  ETA: 0:00:11\u001b[39m\n",
      "\u001b[32mSampling  82%|███████████████████████████████████       |  ETA: 0:00:11\u001b[39m\n",
      "\u001b[32mSampling  82%|███████████████████████████████████       |  ETA: 0:00:11\u001b[39m\n",
      "\u001b[32mSampling  83%|███████████████████████████████████       |  ETA: 0:00:10\u001b[39m\n",
      "\u001b[32mSampling  84%|████████████████████████████████████      |  ETA: 0:00:10\u001b[39m\n",
      "\u001b[32mSampling  84%|████████████████████████████████████      |  ETA: 0:00:10\u001b[39m\n",
      "\u001b[32mSampling  84%|████████████████████████████████████      |  ETA: 0:00:09\u001b[39m\n",
      "\u001b[32mSampling  85%|████████████████████████████████████      |  ETA: 0:00:09\u001b[39m\n",
      "\u001b[32mSampling  86%|████████████████████████████████████      |  ETA: 0:00:09\u001b[39m\n",
      "\u001b[32mSampling  86%|█████████████████████████████████████     |  ETA: 0:00:08\u001b[39m\n",
      "\u001b[32mSampling  86%|█████████████████████████████████████     |  ETA: 0:00:08\u001b[39m\n",
      "\u001b[32mSampling  87%|█████████████████████████████████████     |  ETA: 0:00:08\u001b[39m\n",
      "\u001b[32mSampling  88%|█████████████████████████████████████     |  ETA: 0:00:08\u001b[39m\n",
      "\u001b[32mSampling  88%|█████████████████████████████████████     |  ETA: 0:00:07\u001b[39m\n",
      "\u001b[32mSampling  88%|██████████████████████████████████████    |  ETA: 0:00:07\u001b[39m\n",
      "\u001b[32mSampling  89%|██████████████████████████████████████    |  ETA: 0:00:07\u001b[39m\n",
      "\u001b[32mSampling  90%|██████████████████████████████████████    |  ETA: 0:00:06\u001b[39m\n",
      "\u001b[32mSampling  90%|██████████████████████████████████████    |  ETA: 0:00:06\u001b[39m\n",
      "\u001b[32mSampling  90%|███████████████████████████████████████   |  ETA: 0:00:06\u001b[39m\n",
      "\u001b[32mSampling  91%|███████████████████████████████████████   |  ETA: 0:00:05\u001b[39m\n",
      "\u001b[32mSampling  92%|███████████████████████████████████████   |  ETA: 0:00:05\u001b[39m\n",
      "\u001b[32mSampling  92%|███████████████████████████████████████   |  ETA: 0:00:05\u001b[39m\n",
      "\u001b[32mSampling  92%|███████████████████████████████████████   |  ETA: 0:00:05\u001b[39m\n",
      "\u001b[32mSampling  93%|████████████████████████████████████████  |  ETA: 0:00:04\u001b[39m\n",
      "\u001b[32mSampling  94%|████████████████████████████████████████  |  ETA: 0:00:04\u001b[39m\n",
      "\u001b[32mSampling  94%|████████████████████████████████████████  |  ETA: 0:00:04\u001b[39m\n",
      "\u001b[32mSampling  94%|████████████████████████████████████████  |  ETA: 0:00:03\u001b[39m\n",
      "\u001b[32mSampling  95%|████████████████████████████████████████  |  ETA: 0:00:03\u001b[39m\n",
      "\u001b[32mSampling  96%|█████████████████████████████████████████ |  ETA: 0:00:03\u001b[39m\n",
      "\u001b[32mSampling  96%|█████████████████████████████████████████ |  ETA: 0:00:02\u001b[39m\n",
      "\u001b[32mSampling  96%|█████████████████████████████████████████ |  ETA: 0:00:02\u001b[39m\n",
      "\u001b[32mSampling  97%|█████████████████████████████████████████ |  ETA: 0:00:02\u001b[39m\n",
      "\u001b[32mSampling  98%|█████████████████████████████████████████ |  ETA: 0:00:02\u001b[39m\n",
      "\u001b[32mSampling  98%|██████████████████████████████████████████|  ETA: 0:00:01\u001b[39m\n",
      "\u001b[32mSampling  98%|██████████████████████████████████████████|  ETA: 0:00:01\u001b[39m\n",
      "\u001b[32mSampling  99%|██████████████████████████████████████████|  ETA: 0:00:01\u001b[39m\n",
      "\u001b[32mSampling 100%|██████████████████████████████████████████|  ETA: 0:00:00\u001b[39m\n",
      "\u001b[32mSampling 100%|██████████████████████████████████████████| Time: 0:01:00\u001b[39m\n",
      "\u001b[90mSampling 100%|██████████████████████████████████████████| Time: 0:01:00\u001b[39m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Chains MCMC chain (10000×20×1 Array{Float64, 3}):\n",
       "\n",
       "Iterations        = 1001:1:11000\n",
       "Number of chains  = 1\n",
       "Samples per chain = 10000\n",
       "Wall duration     = 60.3 seconds\n",
       "Compute duration  = 60.3 seconds\n",
       "parameters        = μ_a, sigma, μ_cons[1], σ_cons[1], cons[1], μ_cons[2], σ_cons[2], cons[2]\n",
       "internals         = lp, n_steps, is_accept, acceptance_rate, log_density, hamiltonian_energy, hamiltonian_energy_error, max_hamiltonian_energy_error, tree_depth, numerical_error, step_size, nom_step_size\n",
       "\n",
       "Summary Statistics\n",
       " \u001b[1m parameters \u001b[0m \u001b[1m    mean \u001b[0m \u001b[1m     std \u001b[0m \u001b[1m    mcse \u001b[0m \u001b[1m  ess_bulk \u001b[0m \u001b[1m  ess_tail \u001b[0m \u001b[1m    rhat \u001b[0m \u001b[1m\u001b[0m ⋯\n",
       " \u001b[90m     Symbol \u001b[0m \u001b[90m Float64 \u001b[0m \u001b[90m Float64 \u001b[0m \u001b[90m Float64 \u001b[0m \u001b[90m   Float64 \u001b[0m \u001b[90m   Float64 \u001b[0m \u001b[90m Float64 \u001b[0m \u001b[90m\u001b[0m ⋯\n",
       "\n",
       "         μ_a   -0.0180    5.1360    0.1014   2615.8442   2804.2183    1.0011   ⋯\n",
       "       sigma    5.0648    0.1130    0.0014   6552.0203   5854.6646    1.0014   ⋯\n",
       "   μ_cons[1]    2.2427    1.4007    0.0168   6801.4554   4506.8385    1.0002   ⋯\n",
       "   σ_cons[1]   10.3309    7.0807    0.1173   3170.9611   5033.9139    1.0002   ⋯\n",
       "     cons[1]   -0.4554    5.1377    0.1014   2617.4785   2788.5642    1.0010   ⋯\n",
       "   μ_cons[2]    2.5096    1.4506    0.0158   8004.1009   5478.5748    1.0000   ⋯\n",
       "   σ_cons[2]   10.1607    7.0384    0.1121   2272.5594   1096.7921    1.0002   ⋯\n",
       "     cons[2]    0.4019    5.1374    0.1015   2613.6371   2841.5456    1.0011   ⋯\n",
       "\u001b[36m                                                                1 column omitted\u001b[0m\n",
       "\n",
       "Quantiles\n",
       " \u001b[1m parameters \u001b[0m \u001b[1m     2.5% \u001b[0m \u001b[1m   25.0% \u001b[0m \u001b[1m   50.0% \u001b[0m \u001b[1m   75.0% \u001b[0m \u001b[1m   97.5% \u001b[0m\n",
       " \u001b[90m     Symbol \u001b[0m \u001b[90m  Float64 \u001b[0m \u001b[90m Float64 \u001b[0m \u001b[90m Float64 \u001b[0m \u001b[90m Float64 \u001b[0m \u001b[90m Float64 \u001b[0m\n",
       "\n",
       "         μ_a   -10.6880   -3.0478    0.0983    2.9515   10.6356\n",
       "       sigma     4.8468    4.9897    5.0637    5.1379    5.2941\n",
       "   μ_cons[1]     0.1078    1.0293    2.1307    3.3811    4.8133\n",
       "   σ_cons[1]     0.6071    4.1895    9.1352   15.8122   24.4017\n",
       "     cons[1]   -11.0792   -3.4187   -0.5336    2.5683   10.1901\n",
       "   μ_cons[2]     0.1320    1.2490    2.4939    3.7898    4.8744\n",
       "   σ_cons[2]     0.4409    4.1459    8.8564   15.4545   24.3251\n",
       "     cons[2]   -10.2999   -2.5788    0.2646    3.3952   11.0714\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data_12, contributers_12 = generate_data(cc_12, 1000)\n",
    "model = model_fun7(data_12, contributers_12[1])\n",
    "chain = sample(model, NUTS(), 10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(cons = ([-1.9950906337878604; -5.347828021785617; … ; 13.048937930289512; 12.200154474861817;;], [-1.1938562709053198; -4.536622082188424; … ; 13.415795380109135; 13.091347655847091;;]),)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "c = get(chain, :cons)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AxisMatrix{Float64, Matrix{Float64}, Tuple{Axis{:iter, StepRange{Int64, Int64}}, Axis{:chain, UnitRange{Int64}}}}\u001b[90m (alias for \u001b[39m\u001b[90mAxisArrays.AxisArray{Float64, 2, Array{Float64, 2}, Tuple{AxisArrays.Axis{:iter, StepRange{Int64, Int64}}, AxisArrays.Axis{:chain, UnitRange{Int64}}}}\u001b[39m\u001b[90m)\u001b[39m"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "typeof(c[1][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.026749748878092817"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "mean(mean(c[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.10.0",
   "language": "julia",
   "name": "julia-1.10"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
