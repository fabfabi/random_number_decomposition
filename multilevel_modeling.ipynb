{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [Multilevel Modeling](https://en.wikipedia.org/wiki/Multilevel_model)\n",
    "Idea: Decompose the sum of random numbers into its contributions\n",
    "\n",
    "for a given set of $x_i$ and $a_{ik}$ with\n",
    "$$x_i = \\Sigma_{j=0}^n \\Sigma_{k=1}^{m_j} a_{ik}y_{jk}$$ \n",
    "with\n",
    "* $m_j$ being the number of contributers of layer j\n",
    "* $y_{jk}$ being the k-th contribution of layer j\n",
    "* $m_0 = 1$ by default\n",
    "* $a_{ik} \\in \\{0, 1\\}$\n",
    "* $\\Sigma a_{ik} = 1$ only one contributer per layer\n",
    "\n",
    "calculate the Distributions $y_{k} \\sim N(μ_{k}, σ_{k})$\n",
    "Boundary conditions:\n",
    "* $\\Sigma _{k} μ_k = 0$ via $μ_{m_j} = -\\Sigma_{k = 1}^{m_j-1} μ_{k}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import warnings\n",
    "import matplotlib.pyplot as plt\n",
    "import logging\n",
    "import seaborn as sns\n",
    "import pymc as pm\n",
    "import arviz as az\n",
    "\n",
    "%matplotlib inline\n",
    "plt.style.use('default')\n",
    "\n",
    "logging.basicConfig(format='%(message)s', level=logging.INFO)\n",
    "warnings.filterwarnings(\"ignore\", module=\"scipy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on PyMC v5.16.2\n"
     ]
    }
   ],
   "source": [
    "print(f\"Running on PyMC v{pm.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples = 1000\n",
    "\n",
    "n_contributers = [2, 4] # one influencer in level 1 and 4 on level 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## setup the individual random generators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def align_coefficients(coefs):\n",
    "    \"\"\"ensure that the average over all contributers per level is 0\"\"\"\n",
    "    mem = {}\n",
    "    for level, lcoefs in coefs.items():\n",
    "        avg = np.mean([m for (m, s) in lcoefs.values()])\n",
    "        mem[level] = {k: (m-avg, s) for k, (m,s) in lcoefs.items()}\n",
    "    \n",
    "    return mem\n",
    "def gen_contributer_coefficients(n_contributers, contributer_avg, contributer_sig):\n",
    "    \"\"\"creates for n_contributers the average and standard deviation\n",
    "    Input:\n",
    "    * n_contributers: list with number of influencers for each level\n",
    "    * contributer_avg: average for the average of the influencers\n",
    "    * contributer_sig: average for the stdev for the influencers (lognormal distribution) \n",
    "     \n",
    "    Output:\n",
    "    Dictionary {level : { influencer: (mu, sigma)}} with the coefficients for every\n",
    "    influencer in each level\n",
    "    \"\"\"\n",
    "    assert n_contributers[0] == 1, \"First level is allowed to have one contributer\"\n",
    "    return align_coefficients({lvl : {i : (np.random.normal(contributer_avg), np.random.lognormal(contributer_sig)) for i in range(num)} for lvl, num in enumerate(n_contributers)})\n",
    "\n",
    "def print_coefficients(contributer_coefficients):\n",
    "    contributer_coefficients = align_coefficients(contributer_coefficients)\n",
    "    for m, stage in contributer_coefficients.items():\n",
    "        for i, (mu, sig) in stage.items():\n",
    "            print(f\"Stage {m}: Contributer {i} mu={mu:.2f}, sig={sig:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# easy as a start\n",
    "cc_02 = {0: {    0: (0, 5)},\n",
    "        1: {    0: (0, 1),\n",
    "                1: (0, 1),\n",
    "                2: (0, 1),\n",
    "                3: (4, 2)}}\n",
    "cc_01 = { \n",
    "        0: {    0 : (0, 5)},\n",
    "        1: {    0: (1, 1),\n",
    "                1: (-1, 1)}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stage 0: Contributer 0 mu=0.00, sig=5.00\n",
      "Stage 1: Contributer 0 mu=-1.00, sig=1.00\n",
      "Stage 1: Contributer 1 mu=-1.00, sig=1.00\n",
      "Stage 1: Contributer 2 mu=-1.00, sig=1.00\n",
      "Stage 1: Contributer 3 mu=3.00, sig=2.00\n"
     ]
    }
   ],
   "source": [
    "print_coefficients(cc_02)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_data(contributer_coefficients, n_samples):\n",
    "    \"\"\"generate random data.\n",
    "    The first level defines the baseline that holds for all random numbers\n",
    "    \n",
    "    Inputs:\n",
    "    * n_samples: number of samples\n",
    "    * contributer_coefficients: dictionary with (mean,sig) per level per contributer\n",
    "    \n",
    "    Outputs:\n",
    "    * data: array with the final number\n",
    "    * contributers: matrix defining the contributers, first column is for the first level\"\"\"\n",
    "    \n",
    "    assert len(cc_01[0]) == 1, \"Level 0 defines the baseline. It should have exactly one contributer\"\n",
    "    #data = np.random.normal(gen_avg, gen_sig, n_samples)\n",
    "    data = np.zeros((n_samples, ))\n",
    "    contributers = np.zeros((n_samples, len(contributer_coefficients)))\n",
    "    for lvl, cdict in contributer_coefficients.items():\n",
    "        print(f\"creating level {lvl}\")\n",
    "        lvl_influencers = len(cdict) #number of influencers in this level\n",
    "        lvldata = np.zeros((n_samples, lvl_influencers))\n",
    "\n",
    "        for i, (mu,sig) in cdict.items():\n",
    "            lvldata[:,i] = np.random.normal(mu, sig, n_samples)\n",
    "\n",
    "        selection = np.random.randint(low=0,\n",
    "                                    high=lvl_influencers,\n",
    "                                    size=(n_samples))\n",
    "        contributers[:, lvl] = selection\n",
    "        \n",
    "        data += np.array([lvldata[row, col] for row, col in enumerate(selection)])\n",
    "        # Note: The first level \n",
    "    return data, contributers[:, 1:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling\n",
    "\n",
    "use [Radon Analysis](https://www.pymc.io/projects/examples/en/latest/generalized_linear_models/multilevel_modeling.html) as reference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating level 0\n",
      "creating level 1\n"
     ]
    }
   ],
   "source": [
    "# generate the data\n",
    "data0, contributers = gen_data(n_samples=n_samples,\n",
    "                              contributer_coefficients=cc_01)\n",
    "\n",
    "contributers0 = contributers.squeeze(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "with pm.Model() as model_ref:\n",
    "    \n",
    "    # Priors\n",
    "    a_mu = pm.Normal(\"a_mu\", mu=0.0, sigma=10)\n",
    "    a_sigma = pm.Exponential(\"a_sigma\", 1)\n",
    "\n",
    "    # Data\n",
    "    value = pm.Normal(\"value\", \n",
    "                      mu=a_mu,\n",
    "                      sigma = a_sigma,\n",
    "                      observed = data0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling: [a_mu, a_sigma, value]\n",
      "Sampling: [a_mu, a_sigma, value]\n"
     ]
    }
   ],
   "source": [
    "with model_ref:\n",
    "    prior_checks = pm.sample_prior_predictive()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Auto-assigning NUTS sampler...\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [a_mu, a_sigma]\n",
      "NUTS: [a_mu, a_sigma]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">c:\\Users\\fuerf\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\rich\\live.py:231: UserWarning: install \n",
       "\"ipywidgets\" for Jupyter support\n",
       "  warnings.warn('install \"ipywidgets\" for Jupyter support')\n",
       "</pre>\n"
      ],
      "text/plain": [
       "c:\\Users\\fuerf\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\rich\\live.py:231: UserWarning: install \n",
       "\"ipywidgets\" for Jupyter support\n",
       "  warnings.warn('install \"ipywidgets\" for Jupyter support')\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling 4 chains for 1_000 tune and 1_000 draw iterations (4_000 + 4_000 draws total) took 280 seconds.\n",
      "Sampling 4 chains for 1_000 tune and 1_000 draw iterations (4_000 + 4_000 draws total) took 280 seconds.\n"
     ]
    }
   ],
   "source": [
    "with model_ref:\n",
    "    pooled_trace  = pm.sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>sd</th>\n",
       "      <th>hdi_3%</th>\n",
       "      <th>hdi_97%</th>\n",
       "      <th>mcse_mean</th>\n",
       "      <th>mcse_sd</th>\n",
       "      <th>ess_bulk</th>\n",
       "      <th>ess_tail</th>\n",
       "      <th>r_hat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>a_mu</th>\n",
       "      <td>0.02</td>\n",
       "      <td>0.16</td>\n",
       "      <td>-0.26</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3874.15</td>\n",
       "      <td>2475.96</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a_sigma</th>\n",
       "      <td>5.11</td>\n",
       "      <td>0.12</td>\n",
       "      <td>4.89</td>\n",
       "      <td>5.32</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3717.03</td>\n",
       "      <td>2681.69</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         mean    sd  hdi_3%  hdi_97%  mcse_mean  mcse_sd  ess_bulk  ess_tail  \\\n",
       "a_mu     0.02  0.16   -0.26     0.32        0.0      0.0   3874.15   2475.96   \n",
       "a_sigma  5.11  0.12    4.89     5.32        0.0      0.0   3717.03   2681.69   \n",
       "\n",
       "         r_hat  \n",
       "a_mu       1.0  \n",
       "a_sigma    1.0  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "az.summary(pooled_trace, round_to=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"Dimensions {'contributer'} are unknown to the model and cannot be used to specify a `shape`.\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[22], line 9\u001b[0m\n\u001b[0;32m      6\u001b[0m a_sigma \u001b[38;5;241m=\u001b[39m pm\u001b[38;5;241m.\u001b[39mExponential(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124ma_sigma\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m# contributions\u001b[39;00m\n\u001b[1;32m----> 9\u001b[0m con_sigmas \u001b[38;5;241m=\u001b[39m \u001b[43mpm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mExponential\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcon_sigmas\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdims\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcontributer\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     10\u001b[0m cons \u001b[38;5;241m=\u001b[39m pm\u001b[38;5;241m.\u001b[39mNormal(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcons\u001b[39m\u001b[38;5;124m\"\u001b[39m, mu\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m, sigma \u001b[38;5;241m=\u001b[39m con_sigmas, dims\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontributer\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     12\u001b[0m \u001b[38;5;66;03m# expected value\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\fuerf\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pymc\\distributions\\distribution.py:532\u001b[0m, in \u001b[0;36mDistribution.__new__\u001b[1;34m(cls, name, rng, dims, initval, observed, total_size, transform, default_transform, *args, **kwargs)\u001b[0m\n\u001b[0;32m    530\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m kwargs\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msize\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m kwargs\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mshape\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    531\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m dims \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 532\u001b[0m         kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mshape\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mshape_from_dims\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdims\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    533\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m observed \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    534\u001b[0m         kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mshape\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtuple\u001b[39m(observed\u001b[38;5;241m.\u001b[39mshape)\n",
      "File \u001b[1;32mc:\\Users\\fuerf\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pymc\\distributions\\shape_utils.py:171\u001b[0m, in \u001b[0;36mshape_from_dims\u001b[1;34m(dims, model)\u001b[0m\n\u001b[0;32m    169\u001b[0m unknowndim_dims \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m(dims) \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mset\u001b[39m(model\u001b[38;5;241m.\u001b[39mdim_lengths)\n\u001b[0;32m    170\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m unknowndim_dims:\n\u001b[1;32m--> 171\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\n\u001b[0;32m    172\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDimensions \u001b[39m\u001b[38;5;132;01m{\u001b[39;00munknowndim_dims\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m are unknown to the model and cannot be used to specify a `shape`.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    173\u001b[0m     )\n\u001b[0;32m    175\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mtuple\u001b[39m(model\u001b[38;5;241m.\u001b[39mdim_lengths[dname] \u001b[38;5;28;01mfor\u001b[39;00m dname \u001b[38;5;129;01min\u001b[39;00m dims)\n",
      "\u001b[1;31mKeyError\u001b[0m: \"Dimensions {'contributer'} are unknown to the model and cannot be used to specify a `shape`.\""
     ]
    }
   ],
   "source": [
    "with pm.Model() as model0:\n",
    "    #contributer_idx = pm.MutableData(\"contributer_idx\", contributers0, dims=\"obs_id\")\n",
    "\n",
    "    # Priors\n",
    "    a_mu = pm.Normal(\"a_mu\", mu=0.0, sigma=10)\n",
    "    a_sigma = pm.Exponential(\"a_sigma\", 1)\n",
    "\n",
    "    # contributions\n",
    "    con_sigmas = pm.Exponential(\"con_sigmas\", 1, dims=\"contributer\")\n",
    "    cons = pm.Normal(\"cons\", mu=0, sigma = con_sigmas, dims=\"contributer\")\n",
    "\n",
    "    # expected value\n",
    "    y_hat = a_mu + cons[contributer_idx]\n",
    "    # Data\n",
    "    value = pm.Normal(\"value\", \n",
    "                      mu=y_hat,\n",
    "                      sigma = a_sigma,\n",
    "                      observed = data0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
